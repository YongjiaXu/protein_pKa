{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing on WT_pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka = pd.read_csv('WT_pka.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of null columns due to file \n",
    "WT_pka.drop(WT_pka.columns[-4:], axis = 1, inplace = True)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop more columns that we are now not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.drop(WT_pka.columns[-7:], axis = 1, inplace = True)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = WT_pka.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = WT_pka[row_has_NaN]\n",
    "print(rows_with_NaN)\n",
    "\n",
    "# This row does not have an experimental value, so we drop it\n",
    "WT_pka.dropna(inplace = True)\n",
    "WT_pka.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka['Res ID'] = WT_pka['Res ID'].astype(int)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process irregular values in Expt. pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new column 'Greater/Smaller' to keep record of Expt. pKa\n",
    "WT_pka['Greater/Smaller'] = 0\n",
    "\n",
    "WT_pka.loc[WT_pka['Expt. pKa'].str.contains(\">\"), 'Greater/Smaller'] = 1\n",
    "WT_pka.loc[WT_pka['Expt. pKa'].str.contains(\"<\"), 'Greater/Smaller'] = -1\n",
    "\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('>', '')\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('<', '')\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('~', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two rows with two pKa valus, created a new row to store the second value\n",
    "print(WT_pka[WT_pka['Expt. pKa'].str.contains(\",\")])\n",
    "WT_pka['2nd pKa'] = 0.0\n",
    "WT_pka[['Expt. pKa','2nd pKa']] = WT_pka['Expt. pKa'].str.split(',',expand=True)\n",
    "WT_pka.loc[WT_pka['2nd pKa'] == 'None', '2nd pKa'] = '0'\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].astype(float)\n",
    "\n",
    "WT_pka['2nd pKa'] = WT_pka['2nd pKa'].astype(float)\n",
    "WT_pka['2nd pKa'] = WT_pka['2nd pKa'].fillna(0)\n",
    "\n",
    "WT_pka.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing on individual proteins (pKa.csv and output.pqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create a dataframe for theoretical pka values for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Res Name</th>\n",
       "      <th>pKa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASP</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CYS</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLU</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HIS</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LYS</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TYR</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Res Name   pKa\n",
       "0      ARG  12.0\n",
       "1      ASP   4.0\n",
       "2      CYS   9.5\n",
       "3      GLU   4.4\n",
       "4      HIS   6.3\n",
       "5      LYS  10.4\n",
       "6      TYR   9.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theoretical value of proteins\n",
    "theo_val = {'ARG': 12.0, 'ASP': 4.0, 'CYS': 9.5, 'GLU': 4.4, 'HIS': 6.3, \n",
    "               'LYS': 10.4, 'TYR': 9.6}\n",
    "\n",
    "df_theo_val = pd.DataFrame(np.array([['ARG', 12.0], ['ASP', 4.0], ['CYS', 9.5], \n",
    "                                    ['GLU', 4.4], ['HIS', 6.3], ['LYS', 10.4], ['TYR', 9.6]]), \n",
    "                          columns = ['Res Name', 'pKa'])\n",
    "df_theo_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use 2ovo as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 2ovo pka file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange pKa.csv, we use 2ovo as an example\n",
    "df_2ovo = pd.read_csv('sample_data/2ovo/pKa.csv')\n",
    "df_2ovo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We see that all the columns are now in one column, so we need to split them.\n",
    "df_2ovo[list(df_2ovo.columns)[0].split()] = df_2ovo.iloc[:,0].str.split(expand=True)\n",
    "df_2ovo.drop(df_2ovo.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Split the Res ID and Res Name from ResName\n",
    "# \"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\" split digits and chars\n",
    "df_2ovo[['Res Name', 'Res ID', 'Chain']] = df_2ovo.iloc[:,0].str.split(\"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\", expand=True)\n",
    "df_2ovo.drop(df_2ovo.columns[0], axis = 1, inplace = True)\n",
    "df_2ovo['Res ID'] = df_2ovo['Res ID'].astype(int)\n",
    "df_2ovo = df_2ovo[list(df_2ovo.columns)[-3:-1]+ list(df_2ovo.columns)[0:-3]]\n",
    "df_2ovo = df_2ovo[list(df_2ovo.columns)[0:3]]\n",
    "\n",
    "df_2ovo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with theoretical values\n",
    "df_2ovo.rename(columns={\"pKa\": \"Expt. pKa\"}, inplace=True)\n",
    "df_2ovo = pd.merge(df_2ovo, df_theo_val, on=['Res Name'], how='inner')\n",
    "df_2ovo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 2ovo pqr file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('sample_data/2ovo/output.pqr', 'r')\n",
    "lines = file.readlines()\n",
    "lines = lines[:-1]\n",
    "file.close()\n",
    "column_names = ['Res ID', 'x', 'y', 'z', 'Charge', 'Radius']\n",
    "df_2ovo_pqr = pd.DataFrame(columns=column_names)\n",
    "target_IDs = list(df_2ovo['Res ID'].unique().astype(int))\n",
    "print(target_IDs)\n",
    "i = 0\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    if int(line[5]) in target_IDs:\n",
    "        df_2ovo_pqr.loc[i] = line[5:] \n",
    "        i += 1\n",
    "df_2ovo_pqr['Res ID'] = df_2ovo_pqr['Res ID'].astype(int)\n",
    "df_2ovo_pqr[['x', 'y', 'z', 'Charge', 'Radius']] = df_2ovo_pqr[['x', 'y', 'z', 'Charge', 'Radius']].astype(float)\n",
    "df_2ovo_pqr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2ovo = pd.merge(df_2ovo, df_2ovo_pqr, on=['Res ID'], how='inner')\n",
    "df_2ovo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "res_IDs = list(df_2ovo['Res ID'].unique())\n",
    "data = []\n",
    "\n",
    "for ID in res_IDs:\n",
    "    res_name = list(df_2ovo.loc[(df_2ovo['Res ID']) == ID,'Res Name'].unique())[0]\n",
    "    trace = go.Scatter3d(\n",
    "        x=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'x'],\n",
    "        y=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'y'],\n",
    "        z=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'z'],\n",
    "\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            colorscale='Viridis',   \n",
    "        ),\n",
    "        name= res_name+' '+str(ID),\n",
    "\n",
    "        # list comprehension to add text on hover\n",
    "        text= [f\"x: {a}<br>y: {b}<br>z: {c}\" for a,b,c in list(zip(df_2ovo['x'], df_2ovo['y'], df_2ovo['z']))],\n",
    "        # if you do not want to display x,y,z\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "    data.append(trace)\n",
    "\n",
    "layout = dict(title = 'TEST',)\n",
    "\n",
    "F = dict(data=data, layout=layout)\n",
    "py.offline.plot(F, filename = 'Test.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For any PDBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(PDBID):\n",
    "    df_PDB_csv = pd.read_csv('sample_data/' + PDBID.lower() + '/pKa.csv')\n",
    "    \n",
    "    # We see that all the columns are now in one column, so we need to split them.\n",
    "    df_PDB_csv[list(df_PDB_csv.columns)[0].split()] = df_PDB_csv.iloc[:,0].str.split(expand=True)\n",
    "    df_PDB_csv.drop(df_PDB_csv.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "    # Split the Res ID and Res Name from ResName\n",
    "    # \"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\" split digits and chars\n",
    "    df_PDB_csv[['Res Name', 'Res ID', 'Chain']] = df_PDB_csv.iloc[:,0].str.split(\"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\", expand=True)\n",
    "    df_PDB_csv.drop(df_PDB_csv.columns[0], axis = 1, inplace = True)\n",
    "    df_PDB_csv['Res ID'] = df_PDB_csv['Res ID'].astype(int)\n",
    "    df_PDB_csv = df_PDB_csv[list(df_PDB_csv.columns)[-3:-1]+ list(df_PDB_csv.columns)[0:-3]]\n",
    "    df_PDB_csv = df_PDB_csv[list(df_PDB_csv.columns)[0:3]]\n",
    "    \n",
    "    # merge with theoretical values\n",
    "    df_PDB_csv.rename(columns={\"pKa\": \"Expt. pKa\"}, inplace=True)\n",
    "    df_PDB_csv = pd.merge(df_PDB_csv, df_theo_val, on=['Res Name'], how='inner')\n",
    "    \n",
    "    df_PDB_csv['Expt. pKa'] = df_PDB_csv['Expt. pKa'].astype(float)\n",
    "    df_PDB_csv['pKa'] = df_PDB_csv['pKa'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df_PDB_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pqr(PDBID, df_PDB_csv = None, flag = False):\n",
    "    file = open('sample_data/' + PDBID.lower() + '/output.pqr', 'r')\n",
    "    lines = file.readlines()\n",
    "    lines = lines[:-1]\n",
    "    file.close()\n",
    "    \n",
    "    column_names = ['Atom Name', 'Res Name', 'Res ID', 'x', 'y', 'z', 'Charge', 'Radius']\n",
    "    df_PDB_pqr = pd.DataFrame(columns=column_names)\n",
    "    if flag:\n",
    "        target_IDs = list(df_PDB_csv['Res ID'].unique().astype(int))\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    # find corresponding res ID in pqr file\n",
    "    for line in lines:\n",
    "        line = line.strip().split()\n",
    "        if len(line) == 11:\n",
    "            if flag == False:\n",
    "                df_PDB_pqr.loc[i] = [line[2]] + [line[3]] + line[5:]\n",
    "            elif ((flag) & (int(line[5]) in target_IDs)):\n",
    "                df_PDB_pqr.loc[i] = [line[2]] + [line[3]] + line[5:]\n",
    "            i += 1\n",
    "            \n",
    "    # convert datatype\n",
    "    df_PDB_pqr['Res ID'] = df_PDB_pqr['Res ID'].astype(int)\n",
    "    df_PDB_pqr[['x', 'y', 'z', 'Charge', 'Radius']] = df_PDB_pqr[['x', 'y', 'z', 'Charge', 'Radius']].astype(float)\n",
    "    df_PDB_pqr.head()\n",
    "    return df_PDB_pqr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization on a protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PDB(PDBID, df_PDB):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    res_IDs = list(df_PDB['Res ID'].unique())\n",
    "    data = []\n",
    "\n",
    "    for ID in res_IDs:\n",
    "        res_name = list(df_PDB.loc[(df_PDB['Res ID']) == ID,'Res Name'].unique())[0]\n",
    "        trace = go.Scatter3d(\n",
    "            x=df_PDB.loc[(df_PDB['Res ID']) == ID,'x'],\n",
    "            y=df_PDB.loc[(df_PDB['Res ID']) == ID,'y'],\n",
    "            z=df_PDB.loc[(df_PDB['Res ID']) == ID,'z'],\n",
    "\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                colorscale='Viridis',   \n",
    "            ),\n",
    "            name = res_name + ' ' + str(ID),\n",
    "            # list comprehension to add text on hover\n",
    "            text = [f\"x: {a}<br>y: {b}<br>z: {c}<br>res: {d}\" \n",
    "                   for a,b,c,d in list(zip(df_PDB['x'], df_PDB['y'], df_PDB['z'], [res_name + ' ' + str(ID)]*len(df_PDB['x']))) ],\n",
    "            # if you do not want to display x,y,z\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "        fig.add_trace(trace)\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = dict(title = PDBID.upper(),)\n",
    "\n",
    "    F = dict(data=data, layout=layout)\n",
    "    py.offline.plot(F, filename = 'sample_graphs/' +PDBID + '2.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_PDB(PDBID):\n",
    "    df_PDB_csv = read_csv(PDBID)\n",
    "    df_PDB_pqr = read_pqr(PDBID, df_PDB_csv, flag = True)\n",
    "    # merge csv and pqr\n",
    "    df_PDB = pd.merge(df_PDB_csv, df_PDB_pqr, on=['Res ID', 'Res Name'], how='inner')\n",
    "    plot_PDB(PDBID, df_PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = ['1bf4', '1bpi', '1igd', '1pga', '1pgb', '2ci2', '2ovo', '2qmt', '3ebx', '4pti']\n",
    "# for PDBID in sample_data:\n",
    "#     analyze_PDB(PDBID)\n",
    "df_PDB_pqr = read_pqr('1bf4')\n",
    "# plot_PDB('1bf4', df_PDB_pqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data for Prediction\n",
    "- Purpose here is to analyze the same amino acid and see if there's a pattern even amoung different proteins\n",
    "- We will first use LYS and our sample_data as an experiment. Things we need to do:\n",
    "    - Calculate Coulomb force on each LYS atom from all the other atoms (since looping in python is terrible, we might use matrix?)\n",
    "    - We need to extract all rows of LYS from our sample proteins\n",
    "    - The features that we are interested in are 'Atom name', 'Res Name', 'Res ID', 'x', 'y', 'z', 'Charge', 'Radius'\n",
    "    - One observation is that for the same atom, its charge and radius are the same. \n",
    "        - Need to confirm if it's true\n",
    "        - We could analyze whether the prediction behaves differently if we replace the numerical value with only the atom if we decide whether it is discrete or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_AA = 'ARG'\n",
    "sample_data = ['1bf4', '1bpi', '1igd', '1pga', '1pgb', '2ci2', '2ovo', '2qmt', '3ebx', '4pti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_AA(PDBID, Amino_Acid):\n",
    "    df_PDB_pqr_all = read_pqr(PDBID)\n",
    "    df_PDB_csv = read_csv(PDBID)\n",
    "    df_PDB_pqr = read_pqr(PDBID, df_PDB_csv)\n",
    "    df_PDB = pd.merge(df_PDB_csv, df_PDB_pqr, on=['Res ID', 'Res Name'], how='inner')\n",
    "    target_rows = df_PDB.loc[(df_PDB['Res Name'] == Amino_Acid)]\n",
    "    return target_rows, df_PDB_pqr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coulomb_force(target_row, df_PDB_pqr_all):\n",
    "    coulomb_force = 0\n",
    "    x = target_row['x']\n",
    "    y = target_row['y']\n",
    "    z = target_row['z']\n",
    "    v_target = np.array((x,y,z))\n",
    "    for index, row in df_PDB_pqr_all.iterrows():\n",
    "        v = np.array((row['x'], row['y'], row['z']))\n",
    "        d = v_target - v\n",
    "        dist = (d @ d)**.5\n",
    "#         dist = np.sqrt((row['x'] - x)**2 + (row['y'] - y)**2 + (row['z'] - z)**2)\n",
    "        if dist == 0:\n",
    "            continue\n",
    "        coulomb_force = coulomb_force + row['Charge']/dist\n",
    "    return coulomb_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_df(PDBID):\n",
    "    df_PDB, df_PDB_pqr_all = extract_with_AA(PDBID, target_AA)\n",
    "    df_PDB['Columb Force'] = 0\n",
    "    for index, row in df_PDB.iterrows():\n",
    "        df_PDB.loc[index, 'Columb Force'] = calculate_coulomb_force(row, df_PDB_pqr_all)\n",
    "    df_PDB['PDBID'] = PDBID.upper()\n",
    "    return df_PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the same Amino Acid in all PDB\n",
    "def concat_DFs(sample_data):\n",
    "    first = True\n",
    "    for PDBID in sample_data:\n",
    "        df_PDB = arrange_df(PDBID)\n",
    "        # rearrange columns\n",
    "        df_PDB = df_PDB[[list(df_PDB.columns)[-1]] + [list(df_PDB.columns)[4]] + \n",
    "                          list(df_PDB.columns)[0:2] + list(df_PDB.columns)[-7:-1] + \n",
    "                          list(df_PDB.columns)[2:4]]\n",
    "        if first:\n",
    "            df_AA = pd.concat([df_PDB])\n",
    "            first = False\n",
    "        else:\n",
    "            df_AA = pd.concat([df_AA, df_PDB])\n",
    "    return df_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_ASP = concat_DFs(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# df_ASP.reset_index(drop=True)\n",
    "df_ASP = df_ASP.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy = df_ASP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy['Diff'] = 0\n",
    "df_ASP_copy['Diff'] = df_ASP_copy['Expt. pKa'] - df_ASP_copy['pKa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = (max(df_ASP_copy['Expt. pKa']) + min(df_ASP_copy['Expt. pKa']))/2\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy['Target'] = 0\n",
    "df_ASP_copy.loc[df_ASP_copy['Expt. pKa'] >= pivot, 'Target'] = 1\n",
    "df_ASP_copy.loc[df_ASP_copy['Expt. pKa'] < pivot, 'Target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy.rename(columns={\"Columb Force\": \"Columb_Force\"}, inplace=True)\n",
    "df_ASP_copy.rename(columns={\"Atom Name\": \"Atom_Name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_df_aa(df_AA):\n",
    "    df_AA = df_AA.reset_index(drop=True)\n",
    "    df_AA['Diff'] = 0\n",
    "    df_AA['Diff'] = df_AA['Expt. pKa'] - df_AA['pKa']\n",
    "    \n",
    "    # find pivot for target\n",
    "    pivot = (max(df_AA['Expt. pKa']) + min(df_AA['Expt. pKa']))/2\n",
    "    \n",
    "    df_AA['Target'] = 0\n",
    "    df_AA.loc[df_AA['Expt. pKa'] >= pivot, 'Target'] = 1\n",
    "    df_AA.loc[df_AA['Expt. pKa'] < pivot, 'Target'] = 0\n",
    "    \n",
    "    # rename column -- should be done at the beginning of data processing*******\n",
    "    df_AA.rename(columns={\"Columb Force\": \"Columb_Force\"}, inplace=True)\n",
    "    df_AA.rename(columns={\"Atom Name\": \"Atom_Name\"}, inplace=True)\n",
    "    return df_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def LR_pred(train_x, train_y, test_x, test_y):\n",
    "\n",
    "    lr_sk = LogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "    lr_sk.fit(train_x,train_y)\n",
    "    yhat = lr_sk.predict(test_x)\n",
    "    return accuracy_score(test_y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_pred(train_x, train_y, test_x, test_y):\n",
    "    my_feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "    # Build a DNN with 3 hidden layers with 30, 20 and 10 hidden nodes each.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # Two hidden layers of 30 and 10 nodes respectively.\n",
    "        hidden_units=[30, 20, 10],\n",
    "        # The model must choose between 2 classes.\n",
    "        n_classes=2)\n",
    "    \n",
    "    classifier.train(\n",
    "        input_fn=lambda: input_fn(train_x, train_y, training=True),\n",
    "        steps=5000)\n",
    "    \n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda: input_fn(test_x, test_y, training=False))\n",
    "    \n",
    "    return eval_result['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_res(target_AA):\n",
    "    df_AA = concat_DFs(sample_data)\n",
    "#     print(df_AA)\n",
    "    df_AA = rearrange_df_aa(df_AA)\n",
    "\n",
    "    train, test = train_test_split(df_AA, test_size=0.2)\n",
    "    \n",
    "    feature_columns = ['x', 'y', 'z', 'Charge', 'Radius', 'Columb_Force']\n",
    "    train_x = train[feature_columns]\n",
    "    train_y = train['Target']\n",
    "\n",
    "    test_x = test[feature_columns]\n",
    "    test_y = test['Target']\n",
    "    \n",
    "    LR_accuracy = LR_pred(train_x, train_y, test_x, test_y)\n",
    "    DNN_accuracy = DNN_pred(train_x, train_y, test_x, test_y)\n",
    "    \n",
    "    return LR_accuracy, DNN_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PDBID Atom Name Res Name  Res ID       x       y       z  Charge  Radius  \\\n",
      "459  1BF4         N      ARG      25  -4.289  21.980  13.379 -0.3479   1.824   \n",
      "460  1BF4         H      ARG      25  -5.714  21.560  13.171  0.2747   0.600   \n",
      "461  1BF4        CA      ARG      25  -4.018  23.372  13.753 -0.2637   1.908   \n",
      "462  1BF4        HA      ARG      25  -2.974  23.543  13.582  0.1560   1.387   \n",
      "463  1BF4         C      ARG      25  -4.304  23.655  15.235  0.7341   1.908   \n",
      "..    ...       ...      ...     ...     ...     ...     ...     ...     ...   \n",
      "139  4PTI      HH11      ARG      53  12.991  35.509  -1.349  0.4478   0.600   \n",
      "140  4PTI      HH12      ARG      53  14.841  35.704  -1.688  0.4478   0.600   \n",
      "141  4PTI       NH2      ARG      53  13.260  34.543   0.660 -0.8627   1.824   \n",
      "142  4PTI      HH21      ARG      53  13.605  34.124   1.500  0.4478   0.600   \n",
      "143  4PTI      HH22      ARG      53  12.410  34.786   0.192  0.4478   0.600   \n",
      "\n",
      "     Columb Force  Expt. pKa   pKa  \n",
      "459      0.421643      12.94  12.0  \n",
      "460     -0.057897      12.94  12.0  \n",
      "461      0.335637      12.94  12.0  \n",
      "462     -0.148362      12.94  12.0  \n",
      "463     -0.727392      12.94  12.0  \n",
      "..            ...        ...   ...  \n",
      "139     -0.150995      12.51  12.0  \n",
      "140     -0.153385      12.51  12.0  \n",
      "141      1.445387      12.51  12.0  \n",
      "142     -0.292828      12.51  12.0  \n",
      "143     -0.193189      12.51  12.0  \n",
      "\n",
      "[528 rows x 12 columns]\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.5769496, step = 0\n",
      "INFO:tensorflow:global_step/sec: 464.855\n",
      "INFO:tensorflow:loss = 0.5658643, step = 100 (0.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.283\n",
      "INFO:tensorflow:loss = 0.493958, step = 200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.738\n",
      "INFO:tensorflow:loss = 0.45264488, step = 300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.862\n",
      "INFO:tensorflow:loss = 0.42961043, step = 400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.094\n",
      "INFO:tensorflow:loss = 0.41662443, step = 500 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.375\n",
      "INFO:tensorflow:loss = 0.3906741, step = 600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.296\n",
      "INFO:tensorflow:loss = 0.39214993, step = 700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.192\n",
      "INFO:tensorflow:loss = 0.39974564, step = 800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.728\n",
      "INFO:tensorflow:loss = 0.38184243, step = 900 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.285\n",
      "INFO:tensorflow:loss = 0.37923494, step = 1000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.201\n",
      "INFO:tensorflow:loss = 0.33400008, step = 1100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.33\n",
      "INFO:tensorflow:loss = 0.34902185, step = 1200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.523\n",
      "INFO:tensorflow:loss = 0.36754787, step = 1300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.952\n",
      "INFO:tensorflow:loss = 0.35904685, step = 1400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.001\n",
      "INFO:tensorflow:loss = 0.33464402, step = 1500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.12\n",
      "INFO:tensorflow:loss = 0.32996562, step = 1600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.762\n",
      "INFO:tensorflow:loss = 0.32737714, step = 1700 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.565\n",
      "INFO:tensorflow:loss = 0.32034147, step = 1800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.554\n",
      "INFO:tensorflow:loss = 0.2938826, step = 1900 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.64\n",
      "INFO:tensorflow:loss = 0.32279903, step = 2000 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.429\n",
      "INFO:tensorflow:loss = 0.29751104, step = 2100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.426\n",
      "INFO:tensorflow:loss = 0.29186085, step = 2200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.241\n",
      "INFO:tensorflow:loss = 0.32149118, step = 2300 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.31\n",
      "INFO:tensorflow:loss = 0.27958083, step = 2400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.33\n",
      "INFO:tensorflow:loss = 0.30757135, step = 2500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.075\n",
      "INFO:tensorflow:loss = 0.29183722, step = 2600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.719\n",
      "INFO:tensorflow:loss = 0.2756182, step = 2700 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.905\n",
      "INFO:tensorflow:loss = 0.28626907, step = 2800 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.405\n",
      "INFO:tensorflow:loss = 0.2846232, step = 2900 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.319\n",
      "INFO:tensorflow:loss = 0.31439573, step = 3000 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.208\n",
      "INFO:tensorflow:loss = 0.25674635, step = 3100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.39\n",
      "INFO:tensorflow:loss = 0.27528116, step = 3200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.773\n",
      "INFO:tensorflow:loss = 0.27252793, step = 3300 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.423\n",
      "INFO:tensorflow:loss = 0.25889307, step = 3400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.202\n",
      "INFO:tensorflow:loss = 0.2774706, step = 3500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.882\n",
      "INFO:tensorflow:loss = 0.2936096, step = 3600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.54\n",
      "INFO:tensorflow:loss = 0.26196536, step = 3700 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.774\n",
      "INFO:tensorflow:loss = 0.2781924, step = 3800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.448\n",
      "INFO:tensorflow:loss = 0.26396942, step = 3900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.451\n",
      "INFO:tensorflow:loss = 0.27590513, step = 4000 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.458\n",
      "INFO:tensorflow:loss = 0.26300067, step = 4100 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.601\n",
      "INFO:tensorflow:loss = 0.25238204, step = 4200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.832\n",
      "INFO:tensorflow:loss = 0.24698168, step = 4300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.33\n",
      "INFO:tensorflow:loss = 0.2345945, step = 4400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.487\n",
      "INFO:tensorflow:loss = 0.24934693, step = 4500 (0.153 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 657.972\n",
      "INFO:tensorflow:loss = 0.2660278, step = 4600 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.015\n",
      "INFO:tensorflow:loss = 0.25764698, step = 4700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.602\n",
      "INFO:tensorflow:loss = 0.2499831, step = 4800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.274\n",
      "INFO:tensorflow:loss = 0.23863697, step = 4900 (0.154 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.2608531.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T15:39:13Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44335s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-15:39:13\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9245283, accuracy_baseline = 0.6415094, auc = 0.9841332, auc_precision_recall = 0.9765057, average_loss = 0.22592425, global_step = 5000, label/mean = 0.35849056, loss = 0.22592425, precision = 0.8947368, prediction/mean = 0.3668483, recall = 0.8947368\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpiwb1okjs/model.ckpt-5000\n",
      "    PDBID Atom Name Res Name  Res ID       x       y      z  Charge  Radius  \\\n",
      "420  1BF4         N      ASP      16  10.613  14.713  5.161 -0.5163   1.824   \n",
      "421  1BF4         H      ASP      16  11.476  13.552  5.558  0.2936   0.600   \n",
      "422  1BF4        CA      ASP      16   9.957  14.708  3.853  0.0381   1.908   \n",
      "423  1BF4        HA      ASP      16  10.290  15.551  3.280  0.0880   1.387   \n",
      "424  1BF4         C      ASP      16   8.445  14.776  4.078  0.5366   1.908   \n",
      "..    ...       ...      ...     ...     ...     ...    ...     ...     ...   \n",
      "165  4PTI       HB2      ASP      50  12.520  29.821  2.535 -0.0122   1.487   \n",
      "166  4PTI        CG      ASP      50  12.813  31.776  3.236  0.7994   1.908   \n",
      "167  4PTI       OD1      ASP      50  12.716  32.875  2.613 -0.8014   1.661   \n",
      "168  4PTI       HD1      ASP      50  12.357  33.539  3.205  0.0000   0.000   \n",
      "169  4PTI       OD2      ASP      50  12.096  31.598  4.247 -0.8014   1.661   \n",
      "\n",
      "     Columb Force  Expt. pKa  pKa  \n",
      "420      0.208499       3.84  4.0  \n",
      "421     -0.472558       3.84  4.0  \n",
      "422     -0.332752       3.84  4.0  \n",
      "423     -0.399930       3.84  4.0  \n",
      "424     -0.923343       3.84  4.0  \n",
      "..            ...        ...  ...  \n",
      "165      0.367030       3.16  4.0  \n",
      "166     -0.708852       3.16  4.0  \n",
      "167      0.859841       3.16  4.0  \n",
      "168     -0.184763       3.16  4.0  \n",
      "169      0.836607       3.16  4.0  \n",
      "\n",
      "[442 rows x 12 columns]\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.9856417, step = 0\n",
      "INFO:tensorflow:global_step/sec: 457.492\n",
      "INFO:tensorflow:loss = 0.6130854, step = 100 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.293\n",
      "INFO:tensorflow:loss = 0.6059078, step = 200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.851\n",
      "INFO:tensorflow:loss = 0.57242244, step = 300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.163\n",
      "INFO:tensorflow:loss = 0.57653725, step = 400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.115\n",
      "INFO:tensorflow:loss = 0.5454495, step = 500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.762\n",
      "INFO:tensorflow:loss = 0.54893225, step = 600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.832\n",
      "INFO:tensorflow:loss = 0.54189855, step = 700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.484\n",
      "INFO:tensorflow:loss = 0.53344405, step = 800 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.178\n",
      "INFO:tensorflow:loss = 0.54419744, step = 900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.23\n",
      "INFO:tensorflow:loss = 0.53524244, step = 1000 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.014\n",
      "INFO:tensorflow:loss = 0.53681326, step = 1100 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.066\n",
      "INFO:tensorflow:loss = 0.5186595, step = 1200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.126\n",
      "INFO:tensorflow:loss = 0.49969938, step = 1300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.477\n",
      "INFO:tensorflow:loss = 0.5101151, step = 1400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.023\n",
      "INFO:tensorflow:loss = 0.5121628, step = 1500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.384\n",
      "INFO:tensorflow:loss = 0.503261, step = 1600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.65\n",
      "INFO:tensorflow:loss = 0.4949501, step = 1700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.385\n",
      "INFO:tensorflow:loss = 0.51712316, step = 1800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.803\n",
      "INFO:tensorflow:loss = 0.483743, step = 1900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.787\n",
      "INFO:tensorflow:loss = 0.49373022, step = 2000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.144\n",
      "INFO:tensorflow:loss = 0.48417497, step = 2100 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.4897775, step = 2200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.428\n",
      "INFO:tensorflow:loss = 0.48580807, step = 2300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.677\n",
      "INFO:tensorflow:loss = 0.47588623, step = 2400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.542\n",
      "INFO:tensorflow:loss = 0.47886017, step = 2500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.125\n",
      "INFO:tensorflow:loss = 0.46660534, step = 2600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.981\n",
      "INFO:tensorflow:loss = 0.46538734, step = 2700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.557\n",
      "INFO:tensorflow:loss = 0.46847773, step = 2800 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.793\n",
      "INFO:tensorflow:loss = 0.46509522, step = 2900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.443\n",
      "INFO:tensorflow:loss = 0.41744387, step = 3000 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.874\n",
      "INFO:tensorflow:loss = 0.45879894, step = 3100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.218\n",
      "INFO:tensorflow:loss = 0.45960048, step = 3200 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.844\n",
      "INFO:tensorflow:loss = 0.46075535, step = 3300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.695\n",
      "INFO:tensorflow:loss = 0.47208107, step = 3400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.099\n",
      "INFO:tensorflow:loss = 0.44972628, step = 3500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.713\n",
      "INFO:tensorflow:loss = 0.4479264, step = 3600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.324\n",
      "INFO:tensorflow:loss = 0.43731004, step = 3700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.668\n",
      "INFO:tensorflow:loss = 0.41981995, step = 3800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.629\n",
      "INFO:tensorflow:loss = 0.42396408, step = 3900 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.203\n",
      "INFO:tensorflow:loss = 0.43034172, step = 4000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.202\n",
      "INFO:tensorflow:loss = 0.44003823, step = 4100 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.984\n",
      "INFO:tensorflow:loss = 0.44760525, step = 4200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.219\n",
      "INFO:tensorflow:loss = 0.42279485, step = 4300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.102\n",
      "INFO:tensorflow:loss = 0.44333056, step = 4400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.227\n",
      "INFO:tensorflow:loss = 0.4104014, step = 4500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.149\n",
      "INFO:tensorflow:loss = 0.42039096, step = 4600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.435\n",
      "INFO:tensorflow:loss = 0.42279047, step = 4700 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.833\n",
      "INFO:tensorflow:loss = 0.42672056, step = 4800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.72\n",
      "INFO:tensorflow:loss = 0.41797453, step = 4900 (0.154 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.42571577.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T15:40:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44685s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-15:40:46\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.7078652, accuracy_baseline = 0.5505618, auc = 0.8446429, auc_precision_recall = 0.8895353, average_loss = 0.48509744, global_step = 5000, label/mean = 0.5505618, loss = 0.48509744, precision = 0.7090909, prediction/mean = 0.58409464, recall = 0.79591835\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpcnh08u8w/model.ckpt-5000\n",
      "    PDBID Atom Name Res Name  Res ID       x       y       z  Charge  Radius  \\\n",
      "308  1BF4         N      GLU      11  16.653  19.682  18.992 -0.5163   1.824   \n",
      "309  1BF4         H      GLU      11  15.164  19.640  19.170  0.2936   0.600   \n",
      "310  1BF4        CA      GLU      11  17.262  19.021  17.841  0.0397   1.908   \n",
      "311  1BF4        HA      GLU      11  18.304  19.272  17.828  0.1105   1.387   \n",
      "312  1BF4         C      GLU      11  16.629  19.507  16.545  0.5366   1.908   \n",
      "..    ...       ...      ...     ...     ...     ...     ...     ...     ...   \n",
      "197  4PTI       HG2      GLU      49   9.660  33.106  -3.373 -0.0425   1.487   \n",
      "198  4PTI        CD      GLU      49   8.525  31.417  -2.847  0.8054   1.908   \n",
      "199  4PTI       OE1      GLU      49   7.573  31.562  -3.638 -0.8188   1.661   \n",
      "200  4PTI       HE1      GLU      49   6.805  31.104  -3.290  0.0000   0.000   \n",
      "201  4PTI       OE2      GLU      49   8.368  30.637  -1.865 -0.8188   1.661   \n",
      "\n",
      "     Columb Force  Expt. pKa  pKa  \n",
      "308      0.207749       3.91  4.4  \n",
      "309     -0.528765       3.91  4.4  \n",
      "310     -0.278513       3.91  4.4  \n",
      "311     -0.381715       3.91  4.4  \n",
      "312     -0.852206       3.91  4.4  \n",
      "..            ...        ...  ...  \n",
      "197      0.240233       3.72  4.4  \n",
      "198     -0.866208       3.72  4.4  \n",
      "199      0.662799       3.72  4.4  \n",
      "200     -0.380903       3.72  4.4  \n",
      "201      0.782873       3.72  4.4  \n",
      "\n",
      "[704 rows x 12 columns]\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.86845577, step = 0\n",
      "INFO:tensorflow:global_step/sec: 455.299\n",
      "INFO:tensorflow:loss = 0.6207305, step = 100 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.322\n",
      "INFO:tensorflow:loss = 0.62250465, step = 200 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.815\n",
      "INFO:tensorflow:loss = 0.56383806, step = 300 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.322\n",
      "INFO:tensorflow:loss = 0.5509949, step = 400 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.149\n",
      "INFO:tensorflow:loss = 0.5492038, step = 500 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.086\n",
      "INFO:tensorflow:loss = 0.55159116, step = 600 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.811\n",
      "INFO:tensorflow:loss = 0.51472056, step = 700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.807\n",
      "INFO:tensorflow:loss = 0.5323461, step = 800 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.252\n",
      "INFO:tensorflow:loss = 0.53796345, step = 900 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.331\n",
      "INFO:tensorflow:loss = 0.53708065, step = 1000 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.644\n",
      "INFO:tensorflow:loss = 0.47415596, step = 1100 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.824\n",
      "INFO:tensorflow:loss = 0.46994334, step = 1200 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.186\n",
      "INFO:tensorflow:loss = 0.45858955, step = 1300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.538\n",
      "INFO:tensorflow:loss = 0.47311005, step = 1400 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.246\n",
      "INFO:tensorflow:loss = 0.48946315, step = 1500 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.809\n",
      "INFO:tensorflow:loss = 0.45876187, step = 1600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.8\n",
      "INFO:tensorflow:loss = 0.46361336, step = 1700 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.473\n",
      "INFO:tensorflow:loss = 0.47844225, step = 1800 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.385\n",
      "INFO:tensorflow:loss = 0.49787596, step = 1900 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.538\n",
      "INFO:tensorflow:loss = 0.4600364, step = 2000 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.61\n",
      "INFO:tensorflow:loss = 0.4518321, step = 2100 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.099\n",
      "INFO:tensorflow:loss = 0.45602447, step = 2200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.644\n",
      "INFO:tensorflow:loss = 0.4212061, step = 2300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.808\n",
      "INFO:tensorflow:loss = 0.43842262, step = 2400 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.469\n",
      "INFO:tensorflow:loss = 0.44558734, step = 2500 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.938\n",
      "INFO:tensorflow:loss = 0.43351912, step = 2600 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.851\n",
      "INFO:tensorflow:loss = 0.45778835, step = 2700 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.006\n",
      "INFO:tensorflow:loss = 0.44041237, step = 2800 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.039\n",
      "INFO:tensorflow:loss = 0.4397948, step = 2900 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 622.339\n",
      "INFO:tensorflow:loss = 0.4322221, step = 3000 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.761\n",
      "INFO:tensorflow:loss = 0.41891807, step = 3100 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.342\n",
      "INFO:tensorflow:loss = 0.42032853, step = 3200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.859\n",
      "INFO:tensorflow:loss = 0.4010457, step = 3300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.548\n",
      "INFO:tensorflow:loss = 0.4071856, step = 3400 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.939\n",
      "INFO:tensorflow:loss = 0.397825, step = 3500 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.54\n",
      "INFO:tensorflow:loss = 0.47857943, step = 3600 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.138\n",
      "INFO:tensorflow:loss = 0.4140963, step = 3700 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.38\n",
      "INFO:tensorflow:loss = 0.41117734, step = 3800 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.329\n",
      "INFO:tensorflow:loss = 0.39135915, step = 3900 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 575.225\n",
      "INFO:tensorflow:loss = 0.39745653, step = 4000 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.673\n",
      "INFO:tensorflow:loss = 0.37815398, step = 4100 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 581.111\n",
      "INFO:tensorflow:loss = 0.39447564, step = 4200 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.301\n",
      "INFO:tensorflow:loss = 0.3807548, step = 4300 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.786\n",
      "INFO:tensorflow:loss = 0.37459436, step = 4400 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 595.28\n",
      "INFO:tensorflow:loss = 0.40375322, step = 4500 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.265\n",
      "INFO:tensorflow:loss = 0.377414, step = 4600 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.919\n",
      "INFO:tensorflow:loss = 0.36551386, step = 4700 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.01\n",
      "INFO:tensorflow:loss = 0.39152864, step = 4800 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.508\n",
      "INFO:tensorflow:loss = 0.39594015, step = 4900 (0.163 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.396715.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T15:42:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45494s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-15:42:46\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.83687943, accuracy_baseline = 0.6241135, auc = 0.94607633, auc_precision_recall = 0.9167896, average_loss = 0.34397322, global_step = 5000, label/mean = 0.37588653, loss = 0.34397322, precision = 0.76785713, prediction/mean = 0.41163707, recall = 0.8113208\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp39tc20ue/model.ckpt-5000\n",
      "    PDBID Atom Name Res Name  Res ID       x       y       z  Charge  Radius  \\\n",
      "186  2OVO         N      HIS      52   9.876   7.301  13.347 -0.4157   1.824   \n",
      "187  2OVO         H      HIS      52   9.627   5.856  13.664  0.2719   0.600   \n",
      "188  2OVO        CA      HIS      52  10.616   7.670  12.127  0.0188   1.908   \n",
      "189  2OVO        HA      HIS      52  10.086   8.500  11.704  0.0881   1.387   \n",
      "190  2OVO         C      HIS      52  10.646   6.565  11.086  0.5973   1.908   \n",
      "191  2OVO         O      HIS      52  10.455   5.355  11.388 -0.5679   1.661   \n",
      "192  2OVO        CB      HIS      52  12.061   8.074  12.469 -0.0462   1.908   \n",
      "193  2OVO       HB1      HIS      52  11.978   8.856  13.198  0.0402   1.487   \n",
      "194  2OVO       HB2      HIS      52  12.538   8.266  11.528  0.0402   1.487   \n",
      "195  2OVO        CG      HIS      52  12.891   6.972  13.137 -0.0266   1.908   \n",
      "196  2OVO       ND1      HIS      52  13.472   5.948  12.411 -0.3811   1.824   \n",
      "197  2OVO       HD1      HIS      52  13.434   5.830  11.419  0.3649   0.600   \n",
      "198  2OVO       CD2      HIS      52  13.151   6.799  14.428  0.1292   1.908   \n",
      "199  2OVO       HD2      HIS      52  12.832   7.436  15.229  0.1147   1.409   \n",
      "200  2OVO       CE1      HIS      52  14.104   5.132  13.296  0.2057   1.908   \n",
      "201  2OVO       HE1      HIS      52  14.656   4.245  13.057  0.1392   1.359   \n",
      "202  2OVO       NE2      HIS      52  13.906   5.651  14.550 -0.5727   1.824   \n",
      "203  2OVO       HE2      HIS      52  14.250   5.264  15.406  0.0000   0.600   \n",
      "72   3EBX         N      HIS       6  21.169   7.976  21.223 -0.4157   1.824   \n",
      "73   3EBX         H      HIS       6  21.569   7.611  19.824  0.2719   0.600   \n",
      "74   3EBX        CA      HIS       6  22.133   7.774  22.381  0.0188   1.908   \n",
      "75   3EBX        HA      HIS       6  21.581   7.480  23.252  0.0881   1.387   \n",
      "76   3EBX         C      HIS       6  22.847   9.087  22.662  0.5973   1.908   \n",
      "77   3EBX         O      HIS       6  22.929   9.993  21.828 -0.5679   1.661   \n",
      "78   3EBX        CB      HIS       6  23.121   6.645  22.100 -0.0462   1.908   \n",
      "79   3EBX       HB1      HIS       6  22.530   5.783  21.864  0.0402   1.487   \n",
      "80   3EBX       HB2      HIS       6  23.793   6.622  22.935  0.0402   1.487   \n",
      "81   3EBX        CG      HIS       6  23.961   6.915  20.898 -0.0266   1.908   \n",
      "82   3EBX       ND1      HIS       6  23.459   6.946  19.618 -0.3811   1.824   \n",
      "83   3EBX       HD1      HIS       6  22.500   6.810  19.368  0.3649   0.600   \n",
      "84   3EBX       CD2      HIS       6  25.301   7.119  20.774  0.1292   1.908   \n",
      "85   3EBX       HD2      HIS       6  26.013   7.177  21.573  0.1147   1.409   \n",
      "86   3EBX       CE1      HIS       6  24.442   7.184  18.773  0.2057   1.908   \n",
      "87   3EBX       HE1      HIS       6  24.348   7.314  17.713  0.1392   1.359   \n",
      "88   3EBX       NE2      HIS       6  25.563   7.233  19.467 -0.5727   1.824   \n",
      "89   3EBX       HE2      HIS       6  26.476   7.340  19.073  0.0000   0.600   \n",
      "90   3EBX         N      HIS      26  21.156  16.369  16.283 -0.4157   1.824   \n",
      "91   3EBX         H      HIS      26  21.006  17.639  15.498  0.2719   0.600   \n",
      "92   3EBX        CA      HIS      26  22.382  16.199  17.089  0.0188   1.908   \n",
      "93   3EBX        HA      HIS      26  22.298  15.418  17.818  0.0881   1.387   \n",
      "94   3EBX         C      HIS      26  22.585  17.556  17.762  0.5973   1.908   \n",
      "95   3EBX         O      HIS      26  22.715  18.611  17.105 -0.5679   1.661   \n",
      "96   3EBX        CB      HIS      26  23.571  15.762  16.222 -0.0462   1.908   \n",
      "97   3EBX       HB1      HIS      26  23.593  16.452  15.402  0.0402   1.487   \n",
      "98   3EBX       HB2      HIS      26  23.420  14.717  16.039  0.0402   1.487   \n",
      "99   3EBX        CG      HIS      26  24.931  15.862  16.863 -0.0266   1.908   \n",
      "100  3EBX       ND1      HIS      26  25.853  14.845  16.853 -0.3811   1.824   \n",
      "101  3EBX       HD1      HIS      26  25.733  13.934  16.459  0.3649   0.600   \n",
      "102  3EBX       CD2      HIS      26  25.467  16.931  17.504  0.1292   1.908   \n",
      "103  3EBX       HD2      HIS      26  25.005  17.881  17.685  0.1147   1.409   \n",
      "104  3EBX       CE1      HIS      26  26.954  15.314  17.478  0.2057   1.908   \n",
      "105  3EBX       HE1      HIS      26  27.867  14.772  17.627  0.1392   1.359   \n",
      "106  3EBX       NE2      HIS      26  26.722  16.534  17.869 -0.5727   1.824   \n",
      "107  3EBX       HE2      HIS      26  27.374  17.103  18.369  0.0000   0.600   \n",
      "\n",
      "     Columb Force  Expt. pKa  pKa  \n",
      "186      0.400783       6.71  6.3  \n",
      "187     -0.310514       6.71  6.3  \n",
      "188      0.045060       6.71  6.3  \n",
      "189     -0.012650       6.71  6.3  \n",
      "190     -0.562095       6.71  6.3  \n",
      "191      0.538617       6.71  6.3  \n",
      "192      0.046720       6.71  6.3  \n",
      "193     -0.082624       6.71  6.3  \n",
      "194     -0.009013       6.71  6.3  \n",
      "195     -0.112768       6.71  6.3  \n",
      "196      0.335330       6.71  6.3  \n",
      "197     -0.489630       6.71  6.3  \n",
      "198     -0.285436       6.71  6.3  \n",
      "199     -0.141377       6.71  6.3  \n",
      "200     -0.350277       6.71  6.3  \n",
      "201     -0.114692       6.71  6.3  \n",
      "202      0.278336       6.71  6.3  \n",
      "203     -0.345097       6.71  6.3  \n",
      "72       0.726969       5.90  6.3  \n",
      "73       0.208420       5.90  6.3  \n",
      "74       0.308224       5.90  6.3  \n",
      "75       0.208135       5.90  6.3  \n",
      "76      -0.341090       5.90  6.3  \n",
      "77       0.771844       5.90  6.3  \n",
      "78       0.302283       5.90  6.3  \n",
      "79       0.173004       5.90  6.3  \n",
      "80       0.196737       5.90  6.3  \n",
      "81       0.194417       5.90  6.3  \n",
      "82       0.733044       5.90  6.3  \n",
      "83       0.048226       5.90  6.3  \n",
      "84      -0.023871       5.90  6.3  \n",
      "85       0.088823       5.90  6.3  \n",
      "86      -0.022636       5.90  6.3  \n",
      "87       0.247903       5.90  6.3  \n",
      "88       0.577033       5.90  6.3  \n",
      "89      -0.074434       5.90  6.3  \n",
      "90       0.646400       5.94  6.3  \n",
      "91      -0.112668       5.94  6.3  \n",
      "92       0.271365       5.94  6.3  \n",
      "93       0.198602       5.94  6.3  \n",
      "94      -0.354994       5.94  6.3  \n",
      "95       0.733477       5.94  6.3  \n",
      "96       0.269372       5.94  6.3  \n",
      "97       0.132594       5.94  6.3  \n",
      "98       0.176702       5.94  6.3  \n",
      "99       0.163234       5.94  6.3  \n",
      "100      0.651212       5.94  6.3  \n",
      "101     -0.096602       5.94  6.3  \n",
      "102      0.007348       5.94  6.3  \n",
      "103      0.156721       5.94  6.3  \n",
      "104     -0.059795       5.94  6.3  \n",
      "105      0.229895       5.94  6.3  \n",
      "106      0.580488       5.94  6.3  \n",
      "107     -0.031020       5.94  6.3  \n",
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.62870514, step = 0\n",
      "INFO:tensorflow:global_step/sec: 433.013\n",
      "INFO:tensorflow:loss = 0.51558757, step = 100 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.442\n",
      "INFO:tensorflow:loss = 0.50554526, step = 200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.244\n",
      "INFO:tensorflow:loss = 0.46778706, step = 300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.914\n",
      "INFO:tensorflow:loss = 0.45684507, step = 400 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 591.268\n",
      "INFO:tensorflow:loss = 0.43153113, step = 500 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.723\n",
      "INFO:tensorflow:loss = 0.40458277, step = 600 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.791\n",
      "INFO:tensorflow:loss = 0.36946833, step = 700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.092\n",
      "INFO:tensorflow:loss = 0.3547132, step = 800 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.032\n",
      "INFO:tensorflow:loss = 0.3284039, step = 900 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.727\n",
      "INFO:tensorflow:loss = 0.3112066, step = 1000 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 541.219\n",
      "INFO:tensorflow:loss = 0.29582873, step = 1100 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.094\n",
      "INFO:tensorflow:loss = 0.29365742, step = 1200 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.176\n",
      "INFO:tensorflow:loss = 0.27204043, step = 1300 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.875\n",
      "INFO:tensorflow:loss = 0.26294118, step = 1400 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.182\n",
      "INFO:tensorflow:loss = 0.25636214, step = 1500 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.287\n",
      "INFO:tensorflow:loss = 0.23999423, step = 1600 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 475.137\n",
      "INFO:tensorflow:loss = 0.23870215, step = 1700 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 510.121\n",
      "INFO:tensorflow:loss = 0.234458, step = 1800 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.387\n",
      "INFO:tensorflow:loss = 0.22278236, step = 1900 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.11\n",
      "INFO:tensorflow:loss = 0.21358246, step = 2000 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.023\n",
      "INFO:tensorflow:loss = 0.20135415, step = 2100 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.768\n",
      "INFO:tensorflow:loss = 0.20209222, step = 2200 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.813\n",
      "INFO:tensorflow:loss = 0.19718128, step = 2300 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.809\n",
      "INFO:tensorflow:loss = 0.19356307, step = 2400 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.028\n",
      "INFO:tensorflow:loss = 0.19077358, step = 2500 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.895\n",
      "INFO:tensorflow:loss = 0.18539438, step = 2600 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 579.257\n",
      "INFO:tensorflow:loss = 0.1835818, step = 2700 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.76\n",
      "INFO:tensorflow:loss = 0.18026866, step = 2800 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.405\n",
      "INFO:tensorflow:loss = 0.17710283, step = 2900 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.786\n",
      "INFO:tensorflow:loss = 0.17525843, step = 3000 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.05\n",
      "INFO:tensorflow:loss = 0.17073347, step = 3100 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 514.205\n",
      "INFO:tensorflow:loss = 0.16617608, step = 3200 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 529.205\n",
      "INFO:tensorflow:loss = 0.16214472, step = 3300 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.663\n",
      "INFO:tensorflow:loss = 0.16322011, step = 3400 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.643\n",
      "INFO:tensorflow:loss = 0.15593207, step = 3500 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 578.119\n",
      "INFO:tensorflow:loss = 0.15189359, step = 3600 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.18\n",
      "INFO:tensorflow:loss = 0.15561846, step = 3700 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.962\n",
      "INFO:tensorflow:loss = 0.1474812, step = 3800 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.06\n",
      "INFO:tensorflow:loss = 0.15331453, step = 3900 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.452\n",
      "INFO:tensorflow:loss = 0.14764562, step = 4000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.397\n",
      "INFO:tensorflow:loss = 0.14338014, step = 4100 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.636\n",
      "INFO:tensorflow:loss = 0.14061803, step = 4200 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.409\n",
      "INFO:tensorflow:loss = 0.14064787, step = 4300 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.934\n",
      "INFO:tensorflow:loss = 0.13804483, step = 4400 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.392\n",
      "INFO:tensorflow:loss = 0.14350262, step = 4500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.48\n",
      "INFO:tensorflow:loss = 0.13718462, step = 4600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.729\n",
      "INFO:tensorflow:loss = 0.13050807, step = 4700 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.878\n",
      "INFO:tensorflow:loss = 0.13299748, step = 4800 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.726\n",
      "INFO:tensorflow:loss = 0.12943943, step = 4900 (0.156 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.12200338.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T15:43:55Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.49710s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-15:43:56\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8181818, accuracy_baseline = 0.6363636, auc = 0.92857146, auc_precision_recall = 0.9088392, average_loss = 0.3455654, global_step = 5000, label/mean = 0.36363637, loss = 0.3455654, precision = 1.0, prediction/mean = 0.22995056, recall = 0.5\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp78l149gl/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "list_AA = ['ARG', 'ASP', 'GLU', 'HIS', 'LYS', 'TYR']\n",
    "accuracy = []\n",
    "time = []\n",
    "for target_AA in list_AA:\n",
    "    \n",
    "    start = timer()\n",
    "    LR_accuracy, DNN_accuracy = pred_by_res(target_AA)\n",
    "    end = timer()\n",
    "    \n",
    "    time.append(end-start)\n",
    "    accuracy.append([target_AA, LR_accuracy, DNN_accuracy])\n",
    "\n",
    "print(time)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-8d652e39563c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m fig.add_trace(go.Scatter(x=list_AA, y=accuracy[:,1],\n\u001b[0m\u001b[1;32m      8\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lines'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     name='Logistice Regression'))\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "accuracy = np.array(accuracy)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list_AA, y=accuracy[:,1],\n",
    "                    mode='lines',\n",
    "                    name='Logistice Regression'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list_AA, y=accuracy[:,2],\n",
    "                    mode='lines',\n",
    "                    name='DNN'))\n",
    "\n",
    "fig.update_xaxes(tickangle=0)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression: predict of Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(df_ASP_copy, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['x', 'y', 'z', 'Charge', 'Radius', 'Columb_Force']\n",
    "train_x = train[feature_columns]\n",
    "train_y = train['Target']\n",
    "\n",
    "test_x = test[feature_columns]\n",
    "test_y = test['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_sk = LogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "lr_sk.fit(train_x,train_y)\n",
    "print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "yhat = lr_sk.predict(test_x)\n",
    "print('Accuracy of: ', accuracy_score(test_y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 20, 10],\n",
    "    # The model must choose between 2 classes.\n",
    "    n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train_x, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test[feature_columns], test['Target'], training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
