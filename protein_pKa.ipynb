{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing on WT_pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka = pd.read_csv('WT_pka.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of null columns due to file \n",
    "WT_pka.drop(WT_pka.columns[-4:], axis = 1, inplace = True)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to drop more columns that we are now not interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.drop(WT_pka.columns[-7:], axis = 1, inplace = True)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_NaN = WT_pka.isnull()\n",
    "row_has_NaN = is_NaN.any(axis=1)\n",
    "rows_with_NaN = WT_pka[row_has_NaN]\n",
    "print(rows_with_NaN)\n",
    "\n",
    "# This row does not have an experimental value, so we drop it\n",
    "WT_pka.dropna(inplace = True)\n",
    "WT_pka.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka['Res ID'] = WT_pka['Res ID'].astype(int)\n",
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process irregular values in Expt. pKa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a new column 'Greater/Smaller' to keep record of Expt. pKa\n",
    "WT_pka['Greater/Smaller'] = 0\n",
    "\n",
    "WT_pka.loc[WT_pka['Expt. pKa'].str.contains(\">\"), 'Greater/Smaller'] = 1\n",
    "WT_pka.loc[WT_pka['Expt. pKa'].str.contains(\"<\"), 'Greater/Smaller'] = -1\n",
    "\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('>', '')\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('<', '')\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].str.replace('~', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are two rows with two pKa valus, created a new row to store the second value\n",
    "print(WT_pka[WT_pka['Expt. pKa'].str.contains(\",\")])\n",
    "WT_pka['2nd pKa'] = 0.0\n",
    "WT_pka[['Expt. pKa','2nd pKa']] = WT_pka['Expt. pKa'].str.split(',',expand=True)\n",
    "WT_pka.loc[WT_pka['2nd pKa'] == 'None', '2nd pKa'] = '0'\n",
    "WT_pka['Expt. pKa'] = WT_pka['Expt. pKa'].astype(float)\n",
    "\n",
    "WT_pka['2nd pKa'] = WT_pka['2nd pKa'].astype(float)\n",
    "WT_pka['2nd pKa'] = WT_pka['2nd pKa'].fillna(0)\n",
    "\n",
    "WT_pka.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_pka.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing on individual proteins (pKa.csv and output.pqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First create a dataframe for theoretical pka values for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Res Name</th>\n",
       "      <th>pKa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASP</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CYS</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLU</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HIS</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LYS</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TYR</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Res Name   pKa\n",
       "0      ARG  12.0\n",
       "1      ASP   4.0\n",
       "2      CYS   9.5\n",
       "3      GLU   4.4\n",
       "4      HIS   6.3\n",
       "5      LYS  10.4\n",
       "6      TYR   9.6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theoretical value of proteins\n",
    "theo_val = {'ARG': 12.0, 'ASP': 4.0, 'CYS': 9.5, 'GLU': 4.4, 'HIS': 6.3, \n",
    "               'LYS': 10.4, 'TYR': 9.6}\n",
    "\n",
    "df_theo_val = pd.DataFrame(np.array([['ARG', 12.0], ['ASP', 4.0], ['CYS', 9.5], \n",
    "                                    ['GLU', 4.4], ['HIS', 6.3], ['LYS', 10.4], ['TYR', 9.6]]), \n",
    "                          columns = ['Res Name', 'pKa'])\n",
    "df_theo_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use 2ovo as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 2ovo pka file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange pKa.csv, we use 2ovo as an example\n",
    "df_2ovo = pd.read_csv('sample_data/2ovo/pKa.csv')\n",
    "df_2ovo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We see that all the columns are now in one column, so we need to split them.\n",
    "df_2ovo[list(df_2ovo.columns)[0].split()] = df_2ovo.iloc[:,0].str.split(expand=True)\n",
    "df_2ovo.drop(df_2ovo.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "# Split the Res ID and Res Name from ResName\n",
    "# \"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\" split digits and chars\n",
    "df_2ovo[['Res Name', 'Res ID', 'Chain']] = df_2ovo.iloc[:,0].str.split(\"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\", expand=True)\n",
    "df_2ovo.drop(df_2ovo.columns[0], axis = 1, inplace = True)\n",
    "df_2ovo['Res ID'] = df_2ovo['Res ID'].astype(int)\n",
    "df_2ovo = df_2ovo[list(df_2ovo.columns)[-3:-1]+ list(df_2ovo.columns)[0:-3]]\n",
    "df_2ovo = df_2ovo[list(df_2ovo.columns)[0:3]]\n",
    "\n",
    "df_2ovo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with theoretical values\n",
    "df_2ovo.rename(columns={\"pKa\": \"Expt. pKa\"}, inplace=True)\n",
    "df_2ovo = pd.merge(df_2ovo, df_theo_val, on=['Res Name'], how='inner')\n",
    "df_2ovo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read 2ovo pqr file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('sample_data/2ovo/output.pqr', 'r')\n",
    "lines = file.readlines()\n",
    "lines = lines[:-1]\n",
    "file.close()\n",
    "column_names = ['Res ID', 'x', 'y', 'z', 'Charge', 'Radius']\n",
    "df_2ovo_pqr = pd.DataFrame(columns=column_names)\n",
    "target_IDs = list(df_2ovo['Res ID'].unique().astype(int))\n",
    "print(target_IDs)\n",
    "i = 0\n",
    "for line in lines:\n",
    "    line = line.strip().split()\n",
    "    if int(line[5]) in target_IDs:\n",
    "        df_2ovo_pqr.loc[i] = line[5:] \n",
    "        i += 1\n",
    "df_2ovo_pqr['Res ID'] = df_2ovo_pqr['Res ID'].astype(int)\n",
    "df_2ovo_pqr[['x', 'y', 'z', 'Charge', 'Radius']] = df_2ovo_pqr[['x', 'y', 'z', 'Charge', 'Radius']].astype(float)\n",
    "df_2ovo_pqr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2ovo = pd.merge(df_2ovo, df_2ovo_pqr, on=['Res ID'], how='inner')\n",
    "df_2ovo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "res_IDs = list(df_2ovo['Res ID'].unique())\n",
    "data = []\n",
    "\n",
    "for ID in res_IDs:\n",
    "    res_name = list(df_2ovo.loc[(df_2ovo['Res ID']) == ID,'Res Name'].unique())[0]\n",
    "    trace = go.Scatter3d(\n",
    "        x=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'x'],\n",
    "        y=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'y'],\n",
    "        z=df_2ovo.loc[(df_2ovo['Res ID']) == ID,'z'],\n",
    "\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=3,\n",
    "            colorscale='Viridis',   \n",
    "        ),\n",
    "        name= res_name+' '+str(ID),\n",
    "\n",
    "        # list comprehension to add text on hover\n",
    "        text= [f\"x: {a}<br>y: {b}<br>z: {c}\" for a,b,c in list(zip(df_2ovo['x'], df_2ovo['y'], df_2ovo['z']))],\n",
    "        # if you do not want to display x,y,z\n",
    "        hoverinfo='text'\n",
    "    )\n",
    "    fig.add_trace(trace)\n",
    "    data.append(trace)\n",
    "\n",
    "layout = dict(title = 'TEST',)\n",
    "\n",
    "F = dict(data=data, layout=layout)\n",
    "py.offline.plot(F, filename = 'Test.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For any PDBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(PDBID):\n",
    "    df_PDB_csv = pd.read_csv('sample_data/' + PDBID.lower() + '/pKa.csv')\n",
    "    \n",
    "    # We see that all the columns are now in one column, so we need to split them.\n",
    "    df_PDB_csv[list(df_PDB_csv.columns)[0].split()] = df_PDB_csv.iloc[:,0].str.split(expand=True)\n",
    "    df_PDB_csv.drop(df_PDB_csv.columns[0], axis = 1, inplace = True)\n",
    "\n",
    "    # Split the Res ID and Res Name from ResName\n",
    "    # \"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\" split digits and chars\n",
    "    df_PDB_csv[['Res Name', 'Res ID', 'Chain']] = df_PDB_csv.iloc[:,0].str.split(\"(?<=\\\\D)(?=\\\\d)|(?<=\\\\d)(?=\\\\D)\", expand=True)\n",
    "    df_PDB_csv.drop(df_PDB_csv.columns[0], axis = 1, inplace = True)\n",
    "    df_PDB_csv['Res ID'] = df_PDB_csv['Res ID'].astype(int)\n",
    "    df_PDB_csv = df_PDB_csv[list(df_PDB_csv.columns)[-3:-1]+ list(df_PDB_csv.columns)[0:-3]]\n",
    "    df_PDB_csv = df_PDB_csv[list(df_PDB_csv.columns)[0:3]]\n",
    "    \n",
    "    # merge with theoretical values\n",
    "    df_PDB_csv.rename(columns={\"pKa\": \"Expt. pKa\"}, inplace=True)\n",
    "    df_PDB_csv = pd.merge(df_PDB_csv, df_theo_val, on=['Res Name'], how='inner')\n",
    "    \n",
    "    df_PDB_csv['Expt. pKa'] = df_PDB_csv['Expt. pKa'].astype(float)\n",
    "    df_PDB_csv['pKa'] = df_PDB_csv['pKa'].astype(float)\n",
    "    \n",
    "    \n",
    "    return df_PDB_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pqr(PDBID, df_PDB_csv = None, flag = False):\n",
    "    file = open('sample_data/' + PDBID.lower() + '/output.pqr', 'r')\n",
    "    lines = file.readlines()\n",
    "    lines = lines[:-1]\n",
    "    file.close()\n",
    "    \n",
    "    column_names = ['Atom Name', 'Res Name', 'Res ID', 'x', 'y', 'z', 'Charge', 'Radius']\n",
    "    df_PDB_pqr = pd.DataFrame(columns=column_names)\n",
    "    if flag:\n",
    "        target_IDs = list(df_PDB_csv['Res ID'].unique().astype(int))\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "    # find corresponding res ID in pqr file\n",
    "    for line in lines:\n",
    "        line = line.strip().split()\n",
    "        if len(line) == 11:\n",
    "            if flag == False:\n",
    "                df_PDB_pqr.loc[i] = [line[2]] + [line[3]] + line[5:]\n",
    "            elif ((flag) & (int(line[5]) in target_IDs)):\n",
    "                df_PDB_pqr.loc[i] = [line[2]] + [line[3]] + line[5:]\n",
    "            i += 1\n",
    "            \n",
    "    # convert datatype\n",
    "    df_PDB_pqr['Res ID'] = df_PDB_pqr['Res ID'].astype(int)\n",
    "    df_PDB_pqr[['x', 'y', 'z', 'Charge', 'Radius']] = df_PDB_pqr[['x', 'y', 'z', 'Charge', 'Radius']].astype(float)\n",
    "    df_PDB_pqr.head()\n",
    "    return df_PDB_pqr\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization on a protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PDB(PDBID, df_PDB):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    res_IDs = list(df_PDB['Res ID'].unique())\n",
    "    data = []\n",
    "\n",
    "    for ID in res_IDs:\n",
    "        res_name = list(df_PDB.loc[(df_PDB['Res ID']) == ID,'Res Name'].unique())[0]\n",
    "        trace = go.Scatter3d(\n",
    "            x=df_PDB.loc[(df_PDB['Res ID']) == ID,'x'],\n",
    "            y=df_PDB.loc[(df_PDB['Res ID']) == ID,'y'],\n",
    "            z=df_PDB.loc[(df_PDB['Res ID']) == ID,'z'],\n",
    "\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                colorscale='Viridis',   \n",
    "            ),\n",
    "            name = res_name + ' ' + str(ID),\n",
    "            # list comprehension to add text on hover\n",
    "            text = [f\"x: {a}<br>y: {b}<br>z: {c}<br>res: {d}\" \n",
    "                   for a,b,c,d in list(zip(df_PDB['x'], df_PDB['y'], df_PDB['z'], [res_name + ' ' + str(ID)]*len(df_PDB['x']))) ],\n",
    "            # if you do not want to display x,y,z\n",
    "            hoverinfo='text'\n",
    "        )\n",
    "        fig.add_trace(trace)\n",
    "        data.append(trace)\n",
    "\n",
    "    layout = dict(title = PDBID.upper(),)\n",
    "\n",
    "    F = dict(data=data, layout=layout)\n",
    "    py.offline.plot(F, filename = 'sample_graphs/' +PDBID + '2.html')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_PDB(PDBID):\n",
    "    df_PDB_csv = read_csv(PDBID)\n",
    "    df_PDB_pqr = read_pqr(PDBID, df_PDB_csv, flag = True)\n",
    "    # merge csv and pqr\n",
    "    df_PDB = pd.merge(df_PDB_csv, df_PDB_pqr, on=['Res ID', 'Res Name'], how='inner')\n",
    "    plot_PDB(PDBID, df_PDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = ['1bf4', '1bpi', '1igd', '1pga', '1pgb', '2ci2', '2ovo', '2qmt', '3ebx', '4pti']\n",
    "# for PDBID in sample_data:\n",
    "#     analyze_PDB(PDBID)\n",
    "df_PDB_pqr = read_pqr('1bf4')\n",
    "# plot_PDB('1bf4', df_PDB_pqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data for Prediction\n",
    "- Purpose here is to analyze the same amino acid and see if there's a pattern even amoung different proteins\n",
    "- We will first use LYS and our sample_data as an experiment. Things we need to do:\n",
    "    - Calculate Coulomb force on each LYS atom from all the other atoms (since looping in python is terrible, we might use matrix?)\n",
    "    - We need to extract all rows of LYS from our sample proteins\n",
    "    - The features that we are interested in are 'Atom name', 'Res Name', 'Res ID', 'x', 'y', 'z', 'Charge', 'Radius'\n",
    "    - One observation is that for the same atom, its charge and radius are the same. \n",
    "        - Need to confirm if it's true\n",
    "        - We could analyze whether the prediction behaves differently if we replace the numerical value with only the atom if we decide whether it is discrete or continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_AA = 'ARG'\n",
    "sample_data = ['1bf4', '1bpi', '1igd', '1pga', '1pgb', '2ci2', '2ovo', '2qmt', '3ebx', '4pti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_AA(PDBID, Amino_Acid):\n",
    "    df_PDB_pqr_all = read_pqr(PDBID)\n",
    "    df_PDB_csv = read_csv(PDBID)\n",
    "    df_PDB_pqr = read_pqr(PDBID, df_PDB_csv)\n",
    "    df_PDB = pd.merge(df_PDB_csv, df_PDB_pqr, on=['Res ID', 'Res Name'], how='inner')\n",
    "    target_rows = df_PDB.loc[(df_PDB['Res Name'] == Amino_Acid)]\n",
    "    return target_rows, df_PDB_pqr_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coulomb_force(target_row, df_PDB_pqr_all):\n",
    "    coulomb_force = 0\n",
    "    x = target_row['x']\n",
    "    y = target_row['y']\n",
    "    z = target_row['z']\n",
    "    v_target = np.array((x,y,z))\n",
    "    for index, row in df_PDB_pqr_all.iterrows():\n",
    "        v = np.array((row['x'], row['y'], row['z']))\n",
    "        d = v_target - v\n",
    "        dist = (d @ d)**.5\n",
    "#         dist = np.sqrt((row['x'] - x)**2 + (row['y'] - y)**2 + (row['z'] - z)**2)\n",
    "        if dist == 0:\n",
    "            continue\n",
    "        coulomb_force = coulomb_force + row['Charge']/dist\n",
    "    return coulomb_force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_df(PDBID):\n",
    "    df_PDB, df_PDB_pqr_all = extract_with_AA(PDBID, target_AA)\n",
    "    df_PDB['Columb Force'] = 0\n",
    "    for index, row in df_PDB.iterrows():\n",
    "        df_PDB.loc[index, 'Columb Force'] = calculate_coulomb_force(row, df_PDB_pqr_all)\n",
    "    df_PDB['PDBID'] = PDBID.upper()\n",
    "    return df_PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the same Amino Acid in all PDB\n",
    "def concat_DFs(sample_data):\n",
    "    first = True\n",
    "    for PDBID in sample_data:\n",
    "        df_PDB = arrange_df(PDBID)\n",
    "        # rearrange columns\n",
    "        df_PDB = df_PDB[[list(df_PDB.columns)[-1]] + [list(df_PDB.columns)[4]] + \n",
    "                          list(df_PDB.columns)[0:2] + list(df_PDB.columns)[-7:-1] + \n",
    "                          list(df_PDB.columns)[2:4]]\n",
    "        if first:\n",
    "            df_AA = pd.concat([df_PDB])\n",
    "            first = False\n",
    "        else:\n",
    "            df_AA = pd.concat([df_AA, df_PDB])\n",
    "    return df_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_ASP = concat_DFs(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "# df_ASP.reset_index(drop=True)\n",
    "df_ASP = df_ASP.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy = df_ASP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy['Diff'] = 0\n",
    "df_ASP_copy['Diff'] = df_ASP_copy['Expt. pKa'] - df_ASP_copy['pKa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = (max(df_ASP_copy['Expt. pKa']) + min(df_ASP_copy['Expt. pKa']))/2\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy['Target'] = 0\n",
    "df_ASP_copy.loc[df_ASP_copy['Expt. pKa'] >= pivot, 'Target'] = 1\n",
    "df_ASP_copy.loc[df_ASP_copy['Expt. pKa'] < pivot, 'Target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ASP_copy.rename(columns={\"Columb Force\": \"Columb_Force\"}, inplace=True)\n",
    "df_ASP_copy.rename(columns={\"Atom Name\": \"Atom_Name\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_df_aa(df_AA):\n",
    "    df_AA = df_AA.reset_index(drop=True)\n",
    "    df_AA['Diff'] = 0\n",
    "    df_AA['Diff'] = df_AA['Expt. pKa'] - df_AA['pKa']\n",
    "    \n",
    "    # find pivot for target\n",
    "    pivot = (max(df_AA['Expt. pKa']) + min(df_AA['Expt. pKa']))/2\n",
    "    \n",
    "    df_AA['Target'] = 0\n",
    "    df_AA.loc[df_AA['Expt. pKa'] >= pivot, 'Target'] = 1\n",
    "    df_AA.loc[df_AA['Expt. pKa'] < pivot, 'Target'] = 0\n",
    "    \n",
    "    # rename column -- should be done at the beginning of data processing*******\n",
    "    df_AA.rename(columns={\"Columb Force\": \"Columb_Force\"}, inplace=True)\n",
    "    df_AA.rename(columns={\"Atom Name\": \"Atom_Name\"}, inplace=True)\n",
    "    return df_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def LR_pred(train_x, train_y, test_x, test_y):\n",
    "\n",
    "    lr_sk = LogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "    lr_sk.fit(train_x,train_y)\n",
    "    yhat = lr_sk.predict(test_x)\n",
    "    return accuracy_score(test_y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN_pred(train_x, train_y, test_x, test_y):\n",
    "    my_feature_columns = []\n",
    "    for key in train_x.keys():\n",
    "        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "    \n",
    "    # Build a DNN with 3 hidden layers with 30, 20 and 10 hidden nodes each.\n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=my_feature_columns,\n",
    "        # Two hidden layers of 30 and 10 nodes respectively.\n",
    "        hidden_units=[30, 20, 10],\n",
    "        # The model must choose between 2 classes.\n",
    "        n_classes=2)\n",
    "    \n",
    "    classifier.train(\n",
    "        input_fn=lambda: input_fn(train_x, train_y, training=True),\n",
    "        steps=5000)\n",
    "    \n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda: input_fn(test_x, test_y, training=False))\n",
    "    \n",
    "    return eval_result['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_by_res(target_AA):\n",
    "    df_AA = concat_DFs(sample_data)\n",
    "    if df_AA.empty:\n",
    "        return -1, -1;\n",
    "    df_AA = rearrange_df_aa(df_AA)\n",
    "\n",
    "    train, test = train_test_split(df_AA, test_size=0.2)\n",
    "    \n",
    "    feature_columns = ['x', 'y', 'z', 'Charge', 'Radius', 'Columb_Force']\n",
    "    train_x = train[feature_columns]\n",
    "    train_y = train['Target']\n",
    "\n",
    "    test_x = test[feature_columns]\n",
    "    test_y = test['Target']\n",
    "    \n",
    "    LR_accuracy = LR_pred(train_x, train_y, test_x, test_y)\n",
    "    DNN_accuracy = DNN_pred(train_x, train_y, test_x, test_y)\n",
    "    \n",
    "    return LR_accuracy, DNN_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.4882636, step = 0\n",
      "INFO:tensorflow:global_step/sec: 454.23\n",
      "INFO:tensorflow:loss = 0.5445696, step = 100 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.963\n",
      "INFO:tensorflow:loss = 0.4026389, step = 200 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.141\n",
      "INFO:tensorflow:loss = 0.39975804, step = 300 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.191\n",
      "INFO:tensorflow:loss = 0.39665192, step = 400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.38\n",
      "INFO:tensorflow:loss = 0.3844823, step = 500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.943\n",
      "INFO:tensorflow:loss = 0.3728364, step = 600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.806\n",
      "INFO:tensorflow:loss = 0.37399164, step = 700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.347\n",
      "INFO:tensorflow:loss = 0.3721266, step = 800 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.481\n",
      "INFO:tensorflow:loss = 0.3654812, step = 900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.06\n",
      "INFO:tensorflow:loss = 0.34386396, step = 1000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.862\n",
      "INFO:tensorflow:loss = 0.35544282, step = 1100 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.36\n",
      "INFO:tensorflow:loss = 0.34653193, step = 1200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.079\n",
      "INFO:tensorflow:loss = 0.30857962, step = 1300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.538\n",
      "INFO:tensorflow:loss = 0.31795192, step = 1400 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.242\n",
      "INFO:tensorflow:loss = 0.3599076, step = 1500 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.698\n",
      "INFO:tensorflow:loss = 0.33371276, step = 1600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.911\n",
      "INFO:tensorflow:loss = 0.31863248, step = 1700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.815\n",
      "INFO:tensorflow:loss = 0.32730222, step = 1800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.24\n",
      "INFO:tensorflow:loss = 0.30747673, step = 1900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.25\n",
      "INFO:tensorflow:loss = 0.32551375, step = 2000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.508\n",
      "INFO:tensorflow:loss = 0.35014707, step = 2100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.902\n",
      "INFO:tensorflow:loss = 0.31377605, step = 2200 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.209\n",
      "INFO:tensorflow:loss = 0.3031403, step = 2300 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.93\n",
      "INFO:tensorflow:loss = 0.29514468, step = 2400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.466\n",
      "INFO:tensorflow:loss = 0.28011408, step = 2500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.849\n",
      "INFO:tensorflow:loss = 0.32477856, step = 2600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.12\n",
      "INFO:tensorflow:loss = 0.3311777, step = 2700 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.205\n",
      "INFO:tensorflow:loss = 0.29501507, step = 2800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.026\n",
      "INFO:tensorflow:loss = 0.3185255, step = 2900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.968\n",
      "INFO:tensorflow:loss = 0.29229262, step = 3000 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.875\n",
      "INFO:tensorflow:loss = 0.28856936, step = 3100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.897\n",
      "INFO:tensorflow:loss = 0.2984383, step = 3200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.695\n",
      "INFO:tensorflow:loss = 0.27205998, step = 3300 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.186\n",
      "INFO:tensorflow:loss = 0.30063054, step = 3400 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.847\n",
      "INFO:tensorflow:loss = 0.32494158, step = 3500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.82\n",
      "INFO:tensorflow:loss = 0.29909596, step = 3600 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.084\n",
      "INFO:tensorflow:loss = 0.2899027, step = 3700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.248\n",
      "INFO:tensorflow:loss = 0.26398355, step = 3800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.323\n",
      "INFO:tensorflow:loss = 0.2799225, step = 3900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.182\n",
      "INFO:tensorflow:loss = 0.27051634, step = 4000 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.412\n",
      "INFO:tensorflow:loss = 0.3048168, step = 4100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.672\n",
      "INFO:tensorflow:loss = 0.28900906, step = 4200 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.14\n",
      "INFO:tensorflow:loss = 0.25441006, step = 4300 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.075\n",
      "INFO:tensorflow:loss = 0.26381928, step = 4400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.179\n",
      "INFO:tensorflow:loss = 0.28103587, step = 4500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.927\n",
      "INFO:tensorflow:loss = 0.2460471, step = 4600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.411\n",
      "INFO:tensorflow:loss = 0.2616132, step = 4700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.984\n",
      "INFO:tensorflow:loss = 0.2512465, step = 4800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.841\n",
      "INFO:tensorflow:loss = 0.27654928, step = 4900 (0.155 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.26719323.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T16:02:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.46531s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-16:02:05\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8301887, accuracy_baseline = 0.6037736, auc = 0.9296875, auc_precision_recall = 0.91244763, average_loss = 0.3301239, global_step = 5000, label/mean = 0.3962264, loss = 0.3301239, precision = 0.77272725, prediction/mean = 0.42372614, recall = 0.8095238\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp2g_q7ifp/model.ckpt-5000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.1804979, step = 0\n",
      "INFO:tensorflow:global_step/sec: 439.417\n",
      "INFO:tensorflow:loss = 0.6563817, step = 100 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.146\n",
      "INFO:tensorflow:loss = 0.67263436, step = 200 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.321\n",
      "INFO:tensorflow:loss = 0.6437622, step = 300 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.913\n",
      "INFO:tensorflow:loss = 0.62591773, step = 400 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.628\n",
      "INFO:tensorflow:loss = 0.64749485, step = 500 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.713\n",
      "INFO:tensorflow:loss = 0.6187973, step = 600 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.939\n",
      "INFO:tensorflow:loss = 0.6080688, step = 700 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.991\n",
      "INFO:tensorflow:loss = 0.61210084, step = 800 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.603\n",
      "INFO:tensorflow:loss = 0.5966503, step = 900 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.54\n",
      "INFO:tensorflow:loss = 0.57611454, step = 1000 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.609\n",
      "INFO:tensorflow:loss = 0.5930546, step = 1100 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 610.589\n",
      "INFO:tensorflow:loss = 0.57862973, step = 1200 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.303\n",
      "INFO:tensorflow:loss = 0.5755811, step = 1300 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.477\n",
      "INFO:tensorflow:loss = 0.57658243, step = 1400 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.563\n",
      "INFO:tensorflow:loss = 0.57177293, step = 1500 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.944\n",
      "INFO:tensorflow:loss = 0.57665175, step = 1600 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.308\n",
      "INFO:tensorflow:loss = 0.5458852, step = 1700 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.203\n",
      "INFO:tensorflow:loss = 0.55747294, step = 1800 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.942\n",
      "INFO:tensorflow:loss = 0.5388056, step = 1900 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 614.571\n",
      "INFO:tensorflow:loss = 0.56151456, step = 2000 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 603.177\n",
      "INFO:tensorflow:loss = 0.54715323, step = 2100 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.455\n",
      "INFO:tensorflow:loss = 0.54994345, step = 2200 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.748\n",
      "INFO:tensorflow:loss = 0.5522731, step = 2300 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.653\n",
      "INFO:tensorflow:loss = 0.5399208, step = 2400 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.917\n",
      "INFO:tensorflow:loss = 0.51665956, step = 2500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.943\n",
      "INFO:tensorflow:loss = 0.5197228, step = 2600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.038\n",
      "INFO:tensorflow:loss = 0.5232156, step = 2700 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.911\n",
      "INFO:tensorflow:loss = 0.516719, step = 2800 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.011\n",
      "INFO:tensorflow:loss = 0.51048064, step = 2900 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.485\n",
      "INFO:tensorflow:loss = 0.51646674, step = 3000 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.638\n",
      "INFO:tensorflow:loss = 0.5057448, step = 3100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.132\n",
      "INFO:tensorflow:loss = 0.5040635, step = 3200 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.557\n",
      "INFO:tensorflow:loss = 0.5050277, step = 3300 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.063\n",
      "INFO:tensorflow:loss = 0.4842291, step = 3400 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.354\n",
      "INFO:tensorflow:loss = 0.49526918, step = 3500 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.756\n",
      "INFO:tensorflow:loss = 0.48624465, step = 3600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.672\n",
      "INFO:tensorflow:loss = 0.48193663, step = 3700 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.557\n",
      "INFO:tensorflow:loss = 0.49015427, step = 3800 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.986\n",
      "INFO:tensorflow:loss = 0.49087825, step = 3900 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.006\n",
      "INFO:tensorflow:loss = 0.48474392, step = 4000 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 590.468\n",
      "INFO:tensorflow:loss = 0.47954682, step = 4100 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 606.417\n",
      "INFO:tensorflow:loss = 0.47986537, step = 4200 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.337\n",
      "INFO:tensorflow:loss = 0.4557491, step = 4300 (0.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.686\n",
      "INFO:tensorflow:loss = 0.4706716, step = 4400 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.496\n",
      "INFO:tensorflow:loss = 0.4453882, step = 4500 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.412\n",
      "INFO:tensorflow:loss = 0.46646312, step = 4600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.067\n",
      "INFO:tensorflow:loss = 0.45816475, step = 4700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.079\n",
      "INFO:tensorflow:loss = 0.46828735, step = 4800 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.754\n",
      "INFO:tensorflow:loss = 0.46061128, step = 4900 (0.152 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.4750985.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T16:03:40Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.44607s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-16:03:40\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.6966292, accuracy_baseline = 0.60674155, auc = 0.86243385, auc_precision_recall = 0.925718, average_loss = 0.47211906, global_step = 5000, label/mean = 0.60674155, loss = 0.47211906, precision = 0.7076923, prediction/mean = 0.6214907, recall = 0.8518519\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmptp1gvuan/model.ckpt-5000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 4.32119, step = 0\n",
      "INFO:tensorflow:global_step/sec: 460.172\n",
      "INFO:tensorflow:loss = 1.1278477, step = 100 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.366\n",
      "INFO:tensorflow:loss = 0.81183845, step = 200 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.703\n",
      "INFO:tensorflow:loss = 0.74454236, step = 300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.212\n",
      "INFO:tensorflow:loss = 0.6473017, step = 400 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.325\n",
      "INFO:tensorflow:loss = 0.6175101, step = 500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.015\n",
      "INFO:tensorflow:loss = 0.6232799, step = 600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.869\n",
      "INFO:tensorflow:loss = 0.59580714, step = 700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.86\n",
      "INFO:tensorflow:loss = 0.58750784, step = 800 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.152\n",
      "INFO:tensorflow:loss = 0.5554112, step = 900 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 642.603\n",
      "INFO:tensorflow:loss = 0.5549691, step = 1000 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.879\n",
      "INFO:tensorflow:loss = 0.5661533, step = 1100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.028\n",
      "INFO:tensorflow:loss = 0.5610213, step = 1200 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.435\n",
      "INFO:tensorflow:loss = 0.54962325, step = 1300 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.608\n",
      "INFO:tensorflow:loss = 0.5520057, step = 1400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.016\n",
      "INFO:tensorflow:loss = 0.53565866, step = 1500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.431\n",
      "INFO:tensorflow:loss = 0.5160158, step = 1600 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.862\n",
      "INFO:tensorflow:loss = 0.49855027, step = 1700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.098\n",
      "INFO:tensorflow:loss = 0.5131945, step = 1800 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.024\n",
      "INFO:tensorflow:loss = 0.49528643, step = 1900 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.5\n",
      "INFO:tensorflow:loss = 0.5103425, step = 2000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.208\n",
      "INFO:tensorflow:loss = 0.5086201, step = 2100 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.451\n",
      "INFO:tensorflow:loss = 0.5095763, step = 2200 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.625\n",
      "INFO:tensorflow:loss = 0.5053673, step = 2300 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.288\n",
      "INFO:tensorflow:loss = 0.49870607, step = 2400 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.488\n",
      "INFO:tensorflow:loss = 0.50104535, step = 2500 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.82\n",
      "INFO:tensorflow:loss = 0.48419738, step = 2600 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 645.032\n",
      "INFO:tensorflow:loss = 0.49170613, step = 2700 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.332\n",
      "INFO:tensorflow:loss = 0.5004413, step = 2800 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.027\n",
      "INFO:tensorflow:loss = 0.4814883, step = 2900 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 651.576\n",
      "INFO:tensorflow:loss = 0.48458925, step = 3000 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.691\n",
      "INFO:tensorflow:loss = 0.48527893, step = 3100 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 636.044\n",
      "INFO:tensorflow:loss = 0.49548626, step = 3200 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.893\n",
      "INFO:tensorflow:loss = 0.48279834, step = 3300 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.661\n",
      "INFO:tensorflow:loss = 0.46097788, step = 3400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.777\n",
      "INFO:tensorflow:loss = 0.48021016, step = 3500 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.851\n",
      "INFO:tensorflow:loss = 0.47672468, step = 3600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.004\n",
      "INFO:tensorflow:loss = 0.47823766, step = 3700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.565\n",
      "INFO:tensorflow:loss = 0.4776281, step = 3800 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.12\n",
      "INFO:tensorflow:loss = 0.48111022, step = 3900 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.186\n",
      "INFO:tensorflow:loss = 0.4549928, step = 4000 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.376\n",
      "INFO:tensorflow:loss = 0.4642713, step = 4100 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.395\n",
      "INFO:tensorflow:loss = 0.46598807, step = 4200 (0.156 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 650.754\n",
      "INFO:tensorflow:loss = 0.4392882, step = 4300 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 638.114\n",
      "INFO:tensorflow:loss = 0.46983188, step = 4400 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.676\n",
      "INFO:tensorflow:loss = 0.45480743, step = 4500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 649.575\n",
      "INFO:tensorflow:loss = 0.45220304, step = 4600 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 639.5\n",
      "INFO:tensorflow:loss = 0.4672308, step = 4700 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.341\n",
      "INFO:tensorflow:loss = 0.46169722, step = 4800 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 647.962\n",
      "INFO:tensorflow:loss = 0.442174, step = 4900 (0.154 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.4558457.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T16:06:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45095s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-16:06:27\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.78723407, accuracy_baseline = 0.5531915, auc = 0.9080179, auc_precision_recall = 0.8997532, average_loss = 0.44076377, global_step = 5000, label/mean = 0.44680852, loss = 0.44076377, precision = 0.9459459, prediction/mean = 0.4336898, recall = 0.5555556\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmph63ry04p/model.ckpt-5000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 0.90541255, step = 0\n",
      "INFO:tensorflow:global_step/sec: 468.679\n",
      "INFO:tensorflow:loss = 0.4704189, step = 100 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.349\n",
      "INFO:tensorflow:loss = 0.4327453, step = 200 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.743\n",
      "INFO:tensorflow:loss = 0.41856867, step = 300 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.475\n",
      "INFO:tensorflow:loss = 0.3948765, step = 400 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.84\n",
      "INFO:tensorflow:loss = 0.40726176, step = 500 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 654.729\n",
      "INFO:tensorflow:loss = 0.38680658, step = 600 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.768\n",
      "INFO:tensorflow:loss = 0.38173234, step = 700 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.664\n",
      "INFO:tensorflow:loss = 0.37385142, step = 800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.894\n",
      "INFO:tensorflow:loss = 0.3639351, step = 900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.041\n",
      "INFO:tensorflow:loss = 0.36226076, step = 1000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.44\n",
      "INFO:tensorflow:loss = 0.34674674, step = 1100 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.157\n",
      "INFO:tensorflow:loss = 0.34931237, step = 1200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.353\n",
      "INFO:tensorflow:loss = 0.33622152, step = 1300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.028\n",
      "INFO:tensorflow:loss = 0.32580298, step = 1400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.279\n",
      "INFO:tensorflow:loss = 0.31586912, step = 1500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.203\n",
      "INFO:tensorflow:loss = 0.30557412, step = 1600 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.588\n",
      "INFO:tensorflow:loss = 0.3029564, step = 1700 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 653.932\n",
      "INFO:tensorflow:loss = 0.3013178, step = 1800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.187\n",
      "INFO:tensorflow:loss = 0.28601947, step = 1900 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.303\n",
      "INFO:tensorflow:loss = 0.29122907, step = 2000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.497\n",
      "INFO:tensorflow:loss = 0.28486678, step = 2100 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.969\n",
      "INFO:tensorflow:loss = 0.27950227, step = 2200 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.573\n",
      "INFO:tensorflow:loss = 0.27443805, step = 2300 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.092\n",
      "INFO:tensorflow:loss = 0.26573274, step = 2400 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.618\n",
      "INFO:tensorflow:loss = 0.2583046, step = 2500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 672.707\n",
      "INFO:tensorflow:loss = 0.2545759, step = 2600 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 664.386\n",
      "INFO:tensorflow:loss = 0.25249583, step = 2700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.136\n",
      "INFO:tensorflow:loss = 0.24095576, step = 2800 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.978\n",
      "INFO:tensorflow:loss = 0.24116462, step = 2900 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.825\n",
      "INFO:tensorflow:loss = 0.2410866, step = 3000 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.133\n",
      "INFO:tensorflow:loss = 0.23366265, step = 3100 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.208\n",
      "INFO:tensorflow:loss = 0.22853158, step = 3200 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 656.904\n",
      "INFO:tensorflow:loss = 0.23173313, step = 3300 (0.152 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 658.069\n",
      "INFO:tensorflow:loss = 0.21860951, step = 3400 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 659.294\n",
      "INFO:tensorflow:loss = 0.21364745, step = 3500 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.997\n",
      "INFO:tensorflow:loss = 0.20881946, step = 3600 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.077\n",
      "INFO:tensorflow:loss = 0.21586095, step = 3700 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.568\n",
      "INFO:tensorflow:loss = 0.20220113, step = 3800 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.259\n",
      "INFO:tensorflow:loss = 0.2044538, step = 3900 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.876\n",
      "INFO:tensorflow:loss = 0.19834119, step = 4000 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.39\n",
      "INFO:tensorflow:loss = 0.19982848, step = 4100 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 662.906\n",
      "INFO:tensorflow:loss = 0.19524069, step = 4200 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 667.824\n",
      "INFO:tensorflow:loss = 0.1908169, step = 4300 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.807\n",
      "INFO:tensorflow:loss = 0.18210316, step = 4400 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.601\n",
      "INFO:tensorflow:loss = 0.17884377, step = 4500 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 626.72\n",
      "INFO:tensorflow:loss = 0.17885947, step = 4600 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.268\n",
      "INFO:tensorflow:loss = 0.18173605, step = 4700 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 658.414\n",
      "INFO:tensorflow:loss = 0.17899531, step = 4800 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.574\n",
      "INFO:tensorflow:loss = 0.17226155, step = 4900 (0.149 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.17386827.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T16:07:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.45296s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-16:07:31\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.72727275, accuracy_baseline = 0.6363636, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.4637531, global_step = 5000, label/mean = 0.6363636, loss = 0.4637531, precision = 1.0, prediction/mean = 0.37449238, recall = 0.5714286\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmp70wmosju/model.ckpt-5000\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.3045137, step = 0\n",
      "INFO:tensorflow:global_step/sec: 449.248\n",
      "INFO:tensorflow:loss = 0.65852726, step = 100 (0.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.547\n",
      "INFO:tensorflow:loss = 0.54616594, step = 200 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.597\n",
      "INFO:tensorflow:loss = 0.5325728, step = 300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.13\n",
      "INFO:tensorflow:loss = 0.4912867, step = 400 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.748\n",
      "INFO:tensorflow:loss = 0.51539505, step = 500 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.629\n",
      "INFO:tensorflow:loss = 0.48820445, step = 600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.612\n",
      "INFO:tensorflow:loss = 0.47121227, step = 700 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.033\n",
      "INFO:tensorflow:loss = 0.48594075, step = 800 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.029\n",
      "INFO:tensorflow:loss = 0.45406651, step = 900 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.608\n",
      "INFO:tensorflow:loss = 0.4775812, step = 1000 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.995\n",
      "INFO:tensorflow:loss = 0.45382127, step = 1100 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.48\n",
      "INFO:tensorflow:loss = 0.44542676, step = 1200 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.052\n",
      "INFO:tensorflow:loss = 0.46284086, step = 1300 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.759\n",
      "INFO:tensorflow:loss = 0.42556906, step = 1400 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 604.939\n",
      "INFO:tensorflow:loss = 0.42087996, step = 1500 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.586\n",
      "INFO:tensorflow:loss = 0.47636753, step = 1600 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.616\n",
      "INFO:tensorflow:loss = 0.44265217, step = 1700 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.227\n",
      "INFO:tensorflow:loss = 0.4468621, step = 1800 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.778\n",
      "INFO:tensorflow:loss = 0.4290688, step = 1900 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.102\n",
      "INFO:tensorflow:loss = 0.42926046, step = 2000 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.418\n",
      "INFO:tensorflow:loss = 0.40020645, step = 2100 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.513\n",
      "INFO:tensorflow:loss = 0.4326154, step = 2200 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.283\n",
      "INFO:tensorflow:loss = 0.445903, step = 2300 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 633.582\n",
      "INFO:tensorflow:loss = 0.44509166, step = 2400 (0.158 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 627.294\n",
      "INFO:tensorflow:loss = 0.44271308, step = 2500 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.906\n",
      "INFO:tensorflow:loss = 0.40674892, step = 2600 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 628.654\n",
      "INFO:tensorflow:loss = 0.39554304, step = 2700 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.537\n",
      "INFO:tensorflow:loss = 0.4168261, step = 2800 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 624.726\n",
      "INFO:tensorflow:loss = 0.42264438, step = 2900 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.845\n",
      "INFO:tensorflow:loss = 0.4176863, step = 3000 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.191\n",
      "INFO:tensorflow:loss = 0.4214337, step = 3100 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.069\n",
      "INFO:tensorflow:loss = 0.41235554, step = 3200 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.745\n",
      "INFO:tensorflow:loss = 0.40885898, step = 3300 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 612.471\n",
      "INFO:tensorflow:loss = 0.40746403, step = 3400 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.314\n",
      "INFO:tensorflow:loss = 0.41143095, step = 3500 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.034\n",
      "INFO:tensorflow:loss = 0.40820944, step = 3600 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.368\n",
      "INFO:tensorflow:loss = 0.4100853, step = 3700 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.287\n",
      "INFO:tensorflow:loss = 0.39740303, step = 3800 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 621.195\n",
      "INFO:tensorflow:loss = 0.39419067, step = 3900 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 600.115\n",
      "INFO:tensorflow:loss = 0.38952667, step = 4000 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 611.736\n",
      "INFO:tensorflow:loss = 0.40025446, step = 4100 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.809\n",
      "INFO:tensorflow:loss = 0.3942892, step = 4200 (0.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.965\n",
      "INFO:tensorflow:loss = 0.44327384, step = 4300 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.578\n",
      "INFO:tensorflow:loss = 0.43715554, step = 4400 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 618.518\n",
      "INFO:tensorflow:loss = 0.4136726, step = 4500 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.386\n",
      "INFO:tensorflow:loss = 0.35871866, step = 4600 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 620.156\n",
      "INFO:tensorflow:loss = 0.36109644, step = 4700 (0.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 623.842\n",
      "INFO:tensorflow:loss = 0.39479685, step = 4800 (0.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 619.92\n",
      "INFO:tensorflow:loss = 0.352631, step = 4900 (0.161 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.40715486.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Layer dnn is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-03-06T16:10:27Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.46515s\n",
      "INFO:tensorflow:Finished evaluation at 2021-03-06-16:10:27\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.8401487, accuracy_baseline = 0.74349445, auc = 0.8769565, auc_precision_recall = 0.7709961, average_loss = 0.37112668, global_step = 5000, label/mean = 0.25650558, loss = 0.34379423, precision = 0.7708333, prediction/mean = 0.29385683, recall = 0.5362319\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/bg/sjf18vvj1l30vdgzyw_lhnhw0000gn/T/tmpl_uw1udk/model.ckpt-5000\n",
      "[103.32381937599985, 95.3458084419999, 118.67536689299959, 63.49124978999953, 176.47000382199985]\n",
      "[['ARG', 0.7924528301886793, 0.8301887], ['ASP', 0.7303370786516854, 0.6966292], ['GLU', 0.5957446808510638, 0.78723407], ['HIS', 0.7272727272727273, 0.72727275], ['LYS', 0.7695167286245354, 0.8401487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "list_AA = ['ARG', 'ASP', 'CYS', 'GLU', 'HIS', 'LYS', 'TYR']\n",
    "skipped = []\n",
    "accuracy = []\n",
    "time = []\n",
    "for target_AA in list_AA:\n",
    "    \n",
    "    start = timer()\n",
    "    LR_accuracy, DNN_accuracy = pred_by_res(target_AA)\n",
    "    end = timer()\n",
    "    if LR_accuracy == -1:\n",
    "        skipped.append(target_AA)\n",
    "        continue;\n",
    "    time.append(end-start)\n",
    "    accuracy.append([target_AA, LR_accuracy, DNN_accuracy])\n",
    "\n",
    "print(time)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.28843747204998\n"
     ]
    }
   ],
   "source": [
    "print(sum(time)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Residue Name</th>\n",
       "      <th>Accuracy of LR(%)</th>\n",
       "      <th>Accuracy of DNN(%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARG</td>\n",
       "      <td>79.25</td>\n",
       "      <td>83.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASP</td>\n",
       "      <td>73.03</td>\n",
       "      <td>69.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLU</td>\n",
       "      <td>59.57</td>\n",
       "      <td>78.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HIS</td>\n",
       "      <td>72.73</td>\n",
       "      <td>72.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LYS</td>\n",
       "      <td>76.95</td>\n",
       "      <td>84.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Residue Name  Accuracy of LR(%)  Accuracy of DNN(%)\n",
       "0          ARG              79.25               83.02\n",
       "1          ASP              73.03               69.66\n",
       "2          GLU              59.57               78.72\n",
       "3          HIS              72.73               72.73\n",
       "4          LYS              76.95               84.01"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_accuracy = pd.DataFrame(accuracy, \n",
    "                          columns = ['Residue Name', 'Accuracy of LR(%)', 'Accuracy of DNN(%)'])\n",
    "df_accuracy['Accuracy of LR(%)'] = df_accuracy['Accuracy of LR(%)'].astype(float) * 100\n",
    "df_accuracy['Accuracy of DNN(%)'] = df_accuracy['Accuracy of DNN(%)'].astype(float) * 100\n",
    "df_accuracy.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "Logistice Regression",
         "type": "scatter",
         "x": [
          "ARG",
          "ASP",
          "CYS",
          "GLU",
          "HIS",
          "LYS",
          "TYR"
         ],
         "y": [
          "0.7924528301886793",
          "0.7303370786516854",
          "0.5957446808510638",
          "0.7272727272727273",
          "0.7695167286245354"
         ]
        },
        {
         "mode": "lines",
         "name": "DNN",
         "type": "scatter",
         "x": [
          "ARG",
          "ASP",
          "CYS",
          "GLU",
          "HIS",
          "LYS",
          "TYR"
         ],
         "y": [
          "0.8301887",
          "0.6966292",
          "0.78723407",
          "0.72727275",
          "0.8401487"
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "tickangle": 0
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"00ab50e0-8b4b-481a-b99b-2c210ce847ae\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"00ab50e0-8b4b-481a-b99b-2c210ce847ae\")) {                    Plotly.newPlot(                        \"00ab50e0-8b4b-481a-b99b-2c210ce847ae\",                        [{\"mode\": \"lines\", \"name\": \"Logistice Regression\", \"type\": \"scatter\", \"x\": [\"ARG\", \"ASP\", \"CYS\", \"GLU\", \"HIS\", \"LYS\", \"TYR\"], \"y\": [\"0.7924528301886793\", \"0.7303370786516854\", \"0.5957446808510638\", \"0.7272727272727273\", \"0.7695167286245354\"]}, {\"mode\": \"lines\", \"name\": \"DNN\", \"type\": \"scatter\", \"x\": [\"ARG\", \"ASP\", \"CYS\", \"GLU\", \"HIS\", \"LYS\", \"TYR\"], \"y\": [\"0.8301887\", \"0.6966292\", \"0.78723407\", \"0.72727275\", \"0.8401487\"]}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"tickangle\": 0}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('00ab50e0-8b4b-481a-b99b-2c210ce847ae');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "accuracy = np.array(accuracy)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=list_AA, y=accuracy[:,1],\n",
    "                    mode='lines',\n",
    "                    name='Logistice Regression'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list_AA, y=accuracy[:,2],\n",
    "                    mode='lines',\n",
    "                    name='DNN'))\n",
    "\n",
    "fig.update_xaxes(tickangle=0)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression: predict of Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(df_ASP_copy, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['x', 'y', 'z', 'Charge', 'Radius', 'Columb_Force']\n",
    "train_x = train[feature_columns]\n",
    "train_y = train['Target']\n",
    "\n",
    "test_x = test[feature_columns]\n",
    "test_y = test['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_sk = LogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "lr_sk.fit(train_x,train_y)\n",
    "print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "yhat = lr_sk.predict(test_x)\n",
    "print('Accuracy of: ', accuracy_score(test_y, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature_columns = []\n",
    "for key in train_x.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30, 20, 10],\n",
    "    # The model must choose between 2 classes.\n",
    "    n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train_x, train_y, training=True),\n",
    "    steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda: input_fn(test[feature_columns], test['Target'], training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:1px solid gray\"> </hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
